{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook is meant for filtering the Gammaproteobacterial contaminants from American Gut samples."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These are the modules we will need for this filtering notebook. Also, we will use the trim_fasta function to trim sequences to 100 nucleotides."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run cluster_utils.ipy\n",
      "import os\n",
      "from functools import partial\n",
      "from tempfile import mktemp\n",
      "from collections import defaultdict\n",
      "from cPickle import loads\n",
      "from itertools import izip\n",
      "\n",
      "from americangut.util import trim_fasta, concatenate_files\n",
      "from americangut.results_utils import (check_file, get_path, get_repository_dir,\n",
      "                                       stage_static_files, \n",
      "                                       parse_identifying_data,\n",
      "                                       count_unique_sequences_per_otu,\n",
      "                                       write_contaminant_fasta)\n",
      "\n",
      "# get the current absolute path\n",
      "current_dir = os.path.abspath('.')\n",
      "\n",
      "# get the path to the American Gut repository \n",
      "repo_dir = get_repository_dir()\n",
      "\n",
      "debug = True\n",
      "\n",
      "# create a place to do work\n",
      "if debug:\n",
      "    prj_name = 'debug'\n",
      "else:\n",
      "    prj_name = '' # fill in your own project name here\n",
      "\n",
      "working_dir = os.path.join(current_dir, prj_name)\n",
      "os.makedirs(prj_name)\n",
      "\n",
      "# path wrapper\n",
      "get_relative_new_path = lambda x: os.path.join(working_dir, x)\n",
      "get_relative_existing_path = partial(get_path, working_dir)\n",
      "submit = partial(submit, prj_name)\n",
      "\n",
      "# set the number of processors parallel tasks will use\n",
      "NUM_PROCS = 30"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These are all the filepaths we will be using throughout this notebook. We set them first so that the notebook can be continued easily if it is not run all at once. We also set the contamination abundance threshold here so that files can be named appropriately."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The reference representative set, taxonomy file, and tree files\n",
      "reference_rep_set = '/shared/gg_13_5/gg_13_5/rep_set/97_otus.fasta' # e.g., path to 97_otus.fasta from Greengenes\n",
      "reference_taxonomy = '/shared/gg_13_5/gg_13_5/taxonomy/97_otu_taxonomy.txt' # e.g., path to 97_otu_taxonomy.txt from Grengenes\n",
      "reference_tree = '/shared/gg_13_5/gg_13_5/trees/97_otus.tree' # e.g., path to 97_otus.tree from Grengenes\n",
      "check_file(reference_rep_set)\n",
      "check_file(reference_taxonomy)\n",
      "check_file(reference_tree)\n",
      "\n",
      "# If a single sequence composes at least this fraction of a gammaproteo\n",
      "# OTU that is identified to be over-representend, flat it as a contaminant.\n",
      "contamination_abundance_threshold = 0.85\n",
      "\n",
      "# The value to pass for the -l option of select_gamma.py;\n",
      "# determines what threshold to use when determining what gamma OTUs are over-represented\n",
      "select_gamma_threshold = 0.03\n",
      "\n",
      "# fill in the names of the sequence and mapping files here. Relative paths will be\n",
      "# interpreted relative to the working_dir (above)\n",
      "if debug:\n",
      "    sequence_files = [\n",
      "        os.path.join(repo_dir, 'data', 'AG_debug', 'test_seqs.fna'),\n",
      "        os.path.join(repo_dir, 'data', 'AG_debug', 'test_seqs_2.fna'),\n",
      "    ]\n",
      "else:\n",
      "    sequence_files = [] # insert your own paths here\n",
      "\n",
      "for f in sequence_files:\n",
      "    check_file(f)\n",
      "\n",
      "#mapping_fp = get_path(os.path.join(repo_dir, 'data', 'AG'), 'AG.txt')\n",
      "if debug:\n",
      "    mapping_fp = os.path.join(repo_dir, 'data', 'AG_debug', 'test_mapping.txt')\n",
      "else:\n",
      "    mapping_fp = '' # insert your own path here\n",
      "\n",
      "check_file(mapping_fp)\n",
      "\n",
      "# N.B.: It is unlikely you will want to change the names/paths of the files below!\n",
      "\n",
      "# Merged sequence files\n",
      "merged_sequences_fp = get_relative_new_path('merged_sequences.fna')\n",
      "merged_sequences_trimmed_100_fp = get_relative_new_path('merged_sequences_trimmed_100.fna')\n",
      "merged_sequences_trimmed_100_fecal_only_fp = get_relative_new_path('merged_sequences_fecal_only_trimmed_100.fna')\n",
      "\n",
      "# File paths for the initial round of OTU picking, which is used to determine the most abundant proteobacterial OTUs\n",
      "pick_otus_trimmed_100_output_dir = get_relative_new_path('otus_trimmed_100')\n",
      "initial_otu_table = os.path.join(pick_otus_trimmed_100_output_dir, 'otu_table.biom')\n",
      "initial_otu_map = os.path.join(pick_otus_trimmed_100_output_dir, 'uclust_ref_picked_otus',\n",
      "                               os.path.splitext(os.path.split(merged_sequences_trimmed_100_fecal_only_fp)[-1])[0]+'_otus.txt')\n",
      "\n",
      "# Files for select_gamma.py, which calculates cumulative abundances\n",
      "gammaproteo_cumulative_abundances_fp = get_relative_new_path('gammaproteo_cumul_abundances.txt')\n",
      "\n",
      "# File paths for the second round of OTU picking, where the full set of sequences are clustered using the most\n",
      "# abundant proteobacterial OTUs as a reference\n",
      "contaminants_fp = get_relative_new_path('contaminants_%f.fna' % contamination_abundance_threshold)\n",
      "contaminant_picking_dir = get_relative_new_path('contaminant_otus_%f' % contamination_abundance_threshold)\n",
      "\n",
      "# The final set of output sequences (after contaminant filtering)\n",
      "filtered_sequences_fp = get_relative_new_path('filtered_sequences_%f.fna' % contamination_abundance_threshold)\n",
      "\n",
      "# The final round of OTU picking, using the filtered_sequences_fp above\n",
      "filtered_otus_dir = get_relative_new_path('filtered_otus_%f' % contamination_abundance_threshold)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "These are settings that facilitate running this notebook in parallel on a Torque-based cluster"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# These are the templates for the command for picking closed reference OTUs\n",
      "closed_ref_template = 'pick_closed_reference_otus.py -i %(input)s -o %(output)s -r %(reference)s -t %(taxonomy)s -aO %(num_procs)s'\n",
      "closed_ref_no_tax_template = 'pick_closed_reference_otus.py -i %(input)s -o %(output)s -r %(reference)s -aO %(num_procs)s'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, we will merge the sequences files into a single sequence file, and the mapping files into a single mapping file."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if len(sequence_files) > 1:\n",
      "    # concatenate all sequence files into one merged sequence file. This can take a while!\n",
      "    with open(merged_sequences_fp, 'w') as merged_seqs:\n",
      "        concatenate_files([open(x, 'U') for x in sequence_files], merged_seqs)\n",
      "elif len(sequence_files) == 1:\n",
      "    merged_sequences_fp = sequence_files[0]\n",
      "else:\n",
      "    raise IOError(\"Must specify at least one sequence file.\")\n",
      "\n",
      "check_file(merged_sequences_fp)\n",
      "    \n",
      "with open(merged_sequences_trimmed_100_fp, 'w') as merged_trimmed_seqs:\n",
      "    trim_fasta(open(merged_sequences_fp, 'U'), merged_trimmed_seqs, 100)\n",
      "\n",
      "check_file(merged_sequences_trimmed_100_fp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When finding Gammaproteobacterial contaminants, we want to consider only fecal samples, so we filter our sequences to contain only those that are associated with fecal samples."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!filter_fasta.py -f $merged_sequences_trimmed_100_fp -o $merged_sequences_trimmed_100_fecal_only_fp --mapping_fp=$mapping_fp --valid_states=\"BODY_SITE:UBERON:feces\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The filtering will proceed according to the following steps:\n",
      "\n",
      "1. Identify the most abundant Gammaproteobactia and select the representative sequences from the most abundant, such that the cumulative abundance of remaining Gammaproteobacteria is no greater than 3%\n",
      "2. Find all sequences in the American Gut sequences that map to these OTUs at 97PI\n",
      "3. Of these sequences, if 90% of them are a single unique sequence, treat this sequnence as a contaminant seqeunce\n",
      "4. Create reference database of these contaminant sequences\n",
      "5. Cluster (at 97PI) the full set of American Gut sequence against this reference set of contaminant sequences\n",
      "6. Remove all that map to those contaminant sequences\n",
      "7. Pick OTUs against the standard reference database (Greengenes 13_5 in this case)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "closed_ref_1_args = {\n",
      "    'input': merged_sequences_trimmed_100_fecal_only_fp,\n",
      "    'output': pick_otus_trimmed_100_output_dir,\n",
      "    'reference': reference_rep_set,\n",
      "    'taxonomy': reference_taxonomy,\n",
      "    'num_procs': NUM_PROCS\n",
      "}\n",
      "closed_ref_1_job = submit(closed_ref_template % closed_ref_1_args)\n",
      "jobs = wait_on([closed_ref_1_job])\n",
      "\n",
      "!select_gamma.py -i $initial_otu_table -o $gammaproteo_cumulative_abundances_fp -l $select_gamma_threshold"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, we need to grab all of our sequences that mapped to each of these OTUs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The IDs generated in the previous step by select_gamma.py\n",
      "gammaproteo_ids = {x.strip().split('\\t')[0] for x in open(gammaproteo_cumulative_abundances_fp, 'U').readlines()}\n",
      "\n",
      "print \"Counting unique sequences\"\n",
      "with open(initial_otu_map, 'U') as otu_map, open(merged_sequences_trimmed_100_fp, 'U') as input_seqs:\n",
      "    unique_counts = count_unique_sequences_per_otu(gammaproteo_ids, otu_map, input_seqs)\n",
      "print \"Done.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "And then write out the sequences that are over the abundance threshold"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Writing contaminant sequences...\"\n",
      "with open(contaminants_fp, 'w') as contaminants_f:\n",
      "    write_contaminant_fasta(unique_counts, contaminants_f, contamination_abundance_threshold)\n",
      "print \"Done.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can now pick OTUs against this FASTA file, which represents the set of contaminant sequences, to identify all sequences in our original merged FASTA file are likely the result of contamination. We will discard these sequences before picking OTUs against our standard reference set.\n",
      "\n",
      "N.B.: If your contaminants.fna file is empty, then no contaminants were detected, and you do not need to proceed any further!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Cluster (at 97PI) the full set of American Gut sequence against this reference set of contaminant sequences"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "closed_ref_2_args = {\n",
      "    'input': merged_sequences_trimmed_100_fp,\n",
      "    'output': contaminant_picking_dir,\n",
      "    'reference': contaminants_fp,\n",
      "    'num_procs': NUM_PROCS\n",
      "}\n",
      "closed_ref_2_job = submit(closed_ref_no_tax_template % closed_ref_2_args)\n",
      "wait_on([closed_ref_2_job])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Remove all that map to those contaminant sequences"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Removing all American Gut sequences that clustered against the contaminant sequences\"\n",
      "contaminant_picking_otu_map = os.path.join(contaminant_picking_dir, 'uclust_ref_picked_otus',\n",
      "                                           os.path.splitext(os.path.split(merged_sequences_trimmed_100_fp)[-1])[0]+'_otus.txt')\n",
      "!filter_fasta.py -f $merged_sequences_trimmed_100_fp -m $contaminant_picking_otu_map -o $filtered_sequences_fp -n\n",
      "print \"Done.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Pick OTUs against the standard reference database"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "closed_ref_3_args = {\n",
      "    'input': filtered_sequences_fp,\n",
      "    'output': filtered_otus_dir,\n",
      "    'reference': reference_rep_set,\n",
      "    'taxonomy': reference_taxonomy,\n",
      "    'num_procs': NUM_PROCS\n",
      "}\n",
      "closed_ref_3_job = submit(closed_ref_template % closed_ref_3_args)\n",
      "wait_on([closed_ref_3_job])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
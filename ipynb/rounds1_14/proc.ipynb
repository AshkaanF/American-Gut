{
 "metadata": {
  "name": "",
  "signature": "sha256:4c708497bb10d95adf0354fa20480b274314a3e5bd57558d33da32d4d18dfa11"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Credentials and notebook discription]\n",
      "\n",
      "<a id=\"intro\"></a>\n",
      "# Preprocessing and File Generation\n",
      "\n",
      "[Introduction text]\n",
      "\n",
      "<a id=\"intro_data\"></a>\n",
      "### Data Sets Generated by this Notebook\n",
      "[dataset text]\n",
      "\n",
      "<a id=\"intro_files\"></a>\n",
      "### Files and File Types\n",
      "[files and file types]\n",
      "\n",
      "<a href=\"#top\">Return to the Table of Contents</a>\n",
      "\n",
      "<a id=\"#reqs\"></a>\n",
      "## Notebook Requirements\n",
      "[Notebook requirements]\n",
      "\n",
      "<a href=\"#top\">Return to the Table of Contents</a>\n",
      "\n",
      "<a id=\"top\"></a>\n",
      "## Table of Contents\n",
      "<ul><li><a href=\"#intro\">Introduction</a>\n",
      "<ul><li><a href=\"#\">Data Sets Generated by This Notebook</a>\n",
      "</li><li><a href=\"#\">Files and File Types</a>\n",
      "</li></ul>\n",
      "</li><li><a href=\"#reqs\">Notebook Requirements</a>\n",
      "</li><li><a href=\"#imports\">Function Imports</a>\n",
      "</li><li><a href=\"#params\">Analysis Parameters</a>\n",
      "<ul><li><a href=\"#params_meta\">Metadata and text file handing Parameters</a>\n",
      "</li><li><a href=\"#params_filt\">Filtering Parameters</a>\n",
      "</li><li><a href=\"#params_rare\">Rarefaction Parameters</a>\n",
      "</li><li><a href=\"#params_split\">Split Parameters</a>\n",
      "</li><li><a href=\"#params_alpha\">Alpha Diversity Parameters</a>\n",
      "</li><li><a href=\"#params_beta\">Beta Diversity Parameters</a>\n",
      "</li></ul>\n",
      "</li><li><a href=\"#datasets\">Data Set Selection</a>\n",
      "</li><li><a href=\"#dir\">Filepaths and Directories</a>\n",
      "<ul><li><a href=\"#dir_base\">Base Directory</a>\n",
      "</li><li><a href=\"#dir_ref\">Reference Directories and Files</a>\n",
      "</li><li><a href=\"#dir_work\">Working Directories and Files</a>\n",
      "</li><li><a href=\"#dir_save\">Output Directories and Files</a>\n",
      "</li></ul>\n",
      "</li><li><a href=\"#download\">Data Download</a>\n",
      "</li><li><a href=\"#map_clean\">Mapping File Clean up</a>\n",
      "<ul><li><a href=\"#map_age\">Age</a>\n",
      "</li><li><a href=\"#map_etoh\">Alcohol Consumption</a>\n",
      "</li><li><a href=\"#map_bmi\">Body Mass Index</a>\n",
      "</li><li><a href=\"#map_date\">Collection Season</a>\n",
      "</li><li><a href=\"#map_loc\">Collection Location</a>\n",
      "</li><li><a href=\"#map_sleep\">Sleep Duration</a>\n",
      "</li></ul>\n",
      "</li><li><a href=\"#subset\">Identification of a Healthy Subset of Adults</a>\n",
      "</li><li><a href=\"#rare\">Whole Table Rarefaction</a>\n",
      "</li><li><a href=\"#alpha\">Whole Table Alpha Diversity</a>\n",
      "</li><li><a href=\"#beta\">Whole Table Beta Diversity</a>\n",
      "</li><li><a href=\"#split\">Split the Whole Table by Body Site</a>\n",
      "</li><li><a href=\"#single\">Select a Single Sample for each Participant</a>\n",
      "</li><li><a href=\"#filt_subset\">Filter the Healthy Subset of Adults</a>\n",
      "</li></ul>\n",
      "\n",
      "<a id=\"imports\"></a>\n",
      "## Function Imports\n",
      "[Description of function imports]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import shutil\n",
      "import copy\n",
      "import datetime\n",
      "\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import skbio\n",
      "\n",
      "from biom import load_table\n",
      "from IPython.display import Image\n",
      "from americangut.diversity_analysis import check_dir, pad_index\n",
      "from americangut.geography_lib import (regions_by_state,\n",
      "                                       us_state_map,\n",
      "                                       canadian_map_english)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"params\"></a>\n",
      "## Analysis Parameters\n",
      "[Analysis parameter import text]\n",
      "\n",
      "<a id=\"params_meta\"></a>\n",
      "### Metadata and text file handling parameters\n",
      "[metadata text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "overwrite = False\n",
      "txt_delim = '\\t'\n",
      "map_index = '#SampleID'\n",
      "map_nas = ['NA', 'no_data', 'unknown', '']\n",
      "write_na = ''\n",
      "date_cols = ['RUN_DATE', 'COLLECTION_DATE', 'BIRTH_DATE', 'SAMPLE_TIME']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"params_rare\"></a>\n",
      "### Rarefaction parameters\n",
      "[Rarefaction Parameter Text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rarefaction_depth = 10000\n",
      "num_rarefactions = 10\n",
      "\n",
      "rare_suffix = '_even10k'\n",
      "raw_suffix = ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"params_split\"></a>\n",
      "### Split Parameters\n",
      "[Split Parameter Text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "split_field = 'BODY_HABITAT'\n",
      "split_prefix = 'UBERON:'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"params_alpha\"></a>\n",
      "### Alpha Diversity Parameters\n",
      "[Alpha Parameters text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "alpha_metrics = 'PD_whole_tree,observed_species,chao1,shannon'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "<a id=\"params_beta\"></a>\n",
      "### Beta Diversity Parameters\n",
      "[Beta Parameters text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "beta_metrics = \"unweighted_unifrac,weighted_unifrac\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"datasets\"></a>\n",
      "## Data Set Selection\n",
      "[otu dataset text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lists all bodysites to be analyzed\n",
      "habitat_sites = ['feces', 'oral cavity', 'skin']\n",
      "all_bodysites = ['fecal', 'oral', 'skin']\n",
      "\n",
      "# Handles healthy subset OTU tables\n",
      "sub_part_sites = {'fecal'}\n",
      "\n",
      "# Handles single sample OTU tables\n",
      "one_samp_sites = {'fecal', 'oral', 'skin'}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"dir\"></a>\n",
      "##File paths and Directories\n",
      "[Filepath text]\n",
      "\n",
      "\n",
      "<a id=\"dir_base\"></a>\n",
      "### Base Directory\n",
      "[Base dir text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# base_dir = os.path.join(os.path.abspath('.'), 'agp_analysis')\n",
      "base_dir = os.path.join('/Users/jwdebelius/Desktop/agp_analysis2')\n",
      "check_dir(base_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "<a id=\"dir_ref\"></a>\n",
      "### Reference Directories and Files\n",
      "[Reference File Text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "gg_13_5_dir = os.path.join(os.path.expanduser('~'), 'lib/Greengenes/gg_13_5_otus')\n",
      "tree_fp = os.path.join(gg_13_5_dir, 'trees/97_otus.tree')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"dir_work\"></a>\n",
      "### Working Directories and Files\n",
      "[Description of working directory]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sets up a directory to save intermediate files and downloads\n",
      "working_dir = os.path.join(base_dir, 'intermediate_files')\n",
      "check_dir(working_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Description of the download directory]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Creates a directory for unprocessed file downloads\n",
      "download_dir = os.path.join(working_dir, 'downloads')\n",
      "check_dir(download_dir)\n",
      "\n",
      "# Sets the filepaths for downloaded files\n",
      "download_otu_fp = os.path.join(download_dir, 'AG_100nt.biom')\n",
      "download_map_fp = os.path.join(download_dir, 'AG_100nt.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Description of the split directory]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Creates a directory for splitting the OTU table by bodysite\n",
      "split_raw_dir = os.path.join(working_dir, 'split_by_bodysite_raw')\n",
      "check_dir(split_raw_dir)\n",
      "split_rare_dir = os.path.join(working_dir, 'split_by_bodysite_rare')\n",
      "check_dir(split_rare_dir)\n",
      "\n",
      "# Sets a pattern for filenames in the split directory\n",
      "split_fn = 'AGP_100nt%s__%s_%s%s__.%s'\n",
      "map_ft = 'txt'\n",
      "otu_ft = 'biom'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Description of the rarefaction filepaths]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Creates a parent directory for rarefaction instances\n",
      "rare_dir = os.path.join(working_dir, 'rarefaction')\n",
      "check_dir(rare_dir)\n",
      "\n",
      "# Sets a pattern for the filenames of the rarefaction files\n",
      "rare_pattern = 'rarefaction_%i_%i.biom'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Description of the alpha diveristy filepaths]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Creates a parent directory for the alpha diversity files\n",
      "alpha_dir = os.path.join(working_dir, 'alpha')\n",
      "check_dir(alpha_dir)\n",
      "\n",
      "# Sets a pattern for the filenames of alpha diversity tables\n",
      "alpha_pattern = 'alpha_rarefaction_%i_%i.txt'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"dir_save\"></a>\n",
      "### Output Directories and Files\n",
      "[Description of output directories]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sets up a directory where all results should be saved\n",
      "data_dir = os.path.join(base_dir, 'sample_data')\n",
      "check_dir(data_dir)\n",
      "\n",
      "# Sets up an all sample directory\n",
      "all_dir = os.path.join(data_dir, 'all')\n",
      "\n",
      "# Creates body-site specific directories\n",
      "for site in all_bodysites:\n",
      "    check_dir(os.path.join(data_dir, site))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Describes the fileset directories]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sets up the file path pattern for the possible sets of sample at each body\n",
      "# site\n",
      "asab_pattern = os.path.join(data_dir, '%s/all_participants_all_samples')\n",
      "assb_pattern = os.path.join(data_dir, '%s/all_participants_one_sample')\n",
      "ssab_pattern = os.path.join(data_dir, '%s/sub_participants_all_samples')\n",
      "sssb_pattern = os.path.join(data_dir, '%s/sub_participants_one_sample')\n",
      "\n",
      "# Checks the filepaths\n",
      "for site in all_bodysites:\n",
      "    check_dir(asab_pattern % site)\n",
      "    if site in one_samp_sites:\n",
      "        check_dir(assb_pattern % site)\n",
      "    if site in sub_part_sites:\n",
      "        check_dir(ssab_pattern % site)\n",
      "    if site in sub_part_sites and site in one_samp_sites:\n",
      "        check_dir(sssb_pattern % site)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Describes the file names found in each directory]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "otu_fn = 'AGP_100nt%s%s%s.biom'\n",
      "map_fn = 'AGP_100nt%s%s%s.txt'\n",
      "uud_fn = 'unweighted_unifrac_AGP_100nt%s%s%s.txt'\n",
      "wud_fn = 'weighted_unifrac_AGP_100nt%s%s%s.txt'\n",
      "\n",
      "sin_fn = 'single_samples.txt'\n",
      "sub_fn = 'subset_samples.txt'\n",
      "\n",
      "site_pad = '_'\n",
      "all_ = ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 62
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"download\"></a>\n",
      "## Data Download\n",
      "[Data download description]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Gets the biom file\n",
      "if not os.path.exists(download_otu_fp) or overwrite:\n",
      "    # Downloads the compressed biom file\n",
      "    !curl -OL https://github.com/biocore/American-Gut/raw/master/data/AG/AG_100nt.biom.gz\n",
      "     # Unzips the biom file\n",
      "    !gunzip ./AG_100nt.biom.gz\n",
      "    # Moves the biom file to its final location\n",
      "    shutil.move(os.path.join(os.path.abspath('.'), 'AG_100nt.biom'), download_otu_fp)\n",
      "\n",
      "# Gets the mapping file\n",
      "if not os.path.exists(download_map_fp) or overwrite:\n",
      "    # Downloads the mapping files\n",
      "    !curl -OL https://github.com/biocore/American-Gut/raw/master/data/AG/AG_100nt.txt\n",
      "    # Moves the file to the download file path\n",
      "    shutil.move(os.path.join('.', 'AG_100nt.txt'), download_map_fp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"map_clean\"></a>\n",
      "## Mapping File Clean up\n",
      "[Clean up Text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Loads the mapping file\n",
      "raw_map = pad_index(pd.read_csv(download_map_fp,\n",
      "                                sep=txt_delim, \n",
      "                                na_values=map_nas,\n",
      "                                index_col=False,\n",
      "                                parse_dates=date_cols,\n",
      "                                infer_datetime_format=True),\n",
      "                    index_col=map_index)\n",
      "\n",
      "# Loads the OTU table\n",
      "raw_otu = load_table(download_otu_fp)\n",
      "\n",
      "# Filters the raw map to remove any samples that are not present in the biom table\n",
      "raw_map = raw_map.loc[raw_otu.ids()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Cleans up the sex information based on a miscoding\n",
      "raw_map.loc[raw_map.SEX == '47', 'SEX'] = 'male'\n",
      "raw_map.loc[raw_map.SEX == '48', 'SEX'] = 'female'\n",
      "\n",
      "# Cleans up age information based on miscodeing\n",
      "raw_map.loc[raw_map.AGE_UNIT == '78', 'AGE_UNIT'] = 'years'\n",
      "\n",
      "# Cleans up handedness based on miscoding\n",
      "raw_map.loc[raw_map.DOMINANT_HAND == '151', 'DOMINANT_HAND'] = 'left'\n",
      "raw_map.loc[raw_map.DOMINANT_HAND == '152', 'DOMINANT_HAND'] = 'right'\n",
      "raw_map.loc[raw_map.DOMINANT_HAND == '153', 'DOMINANT_HAND'] = 'ambidextrous'\n",
      "\n",
      "# Removes the timestamp for any collection date prior to December 1, 2012\n",
      "crit_date = datetime.date(2012, 12, 1)\n",
      "raw_map.loc[raw_map.COLLECTION_DATE < crit_date, 'COLLECTION_DATE'] = pd.NaT"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"map_age\"></a>\n",
      "### Age\n",
      "[Age map text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Bins age by decade (with the exception of young children)\n",
      "def categorize_age(x):\n",
      "    if np.isnan(x):\n",
      "        return x\n",
      "    elif x < 3:\n",
      "        return \"baby\"\n",
      "    elif x < 13:\n",
      "        return \"child\"\n",
      "    elif x < 20:\n",
      "        return \"teen\"\n",
      "    elif x < 30:\n",
      "        return \"20s\"\n",
      "    elif x < 40:\n",
      "        return \"30s\"\n",
      "    elif x < 50:\n",
      "        return \"40s\"\n",
      "    elif x < 60:\n",
      "        return \"50s\"\n",
      "    elif x < 70:\n",
      "        return \"60s\"\n",
      "    else:\n",
      "        return \"70+\"\n",
      "raw_map['AGE_CAT'] = raw_map.AGE.apply(categorize_age)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"map_etoh\"></a>\n",
      "### Alcohol Consumption\n",
      "[Alcohol map text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def categorize_etoh(x):\n",
      "    if x == 'Never':\n",
      "        return \"No\"\n",
      "    elif isinstance(x, str):\n",
      "        return \"Yes\"\n",
      "    elif np.isnan(x):\n",
      "        return x\n",
      "    \n",
      "raw_map['ALCOHOL_CONSUMPTION'] = raw_map.ALCOHOL_FREQUENCY.apply(categorize_etoh)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"map_bmi\"></a>\n",
      "### Body Mass Index\n",
      "[BMI map text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Categorizes the BMI into groups\n",
      "def categorize_bmi(x):\n",
      "    if np.isnan(x):\n",
      "        return x\n",
      "    elif x < 18.5:\n",
      "        return \"Underweight\"\n",
      "    elif x < 25:\n",
      "        return \"Normal\"\n",
      "    elif x < 30:\n",
      "        return \"Overweight\"\n",
      "    else:\n",
      "        return \"Obese\"\n",
      "raw_map['BMI_CAT'] = raw_map.BMI.apply(categorize_bmi)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"map_date\"></a>\n",
      "### Collection Season\n",
      "[date map text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Categorizes data by collection month and collection season\n",
      "month_map = {-1: [np.nan, np.nan],\n",
      "             np.nan: [np.nan, np.nan],\n",
      "             1: ['January', 'Winter'],\n",
      "             2: ['February', 'Winter'],\n",
      "             3: ['March', 'Spring'],\n",
      "             4: ['April', 'Spring'],\n",
      "             5: ['May', 'Spring'],\n",
      "             6: ['June', 'Summer'],\n",
      "             7: ['July', 'Summer'],\n",
      "             8: ['August', 'Summer'],\n",
      "             9: ['September', 'Fall'],\n",
      "             10: ['October', 'Fall'],\n",
      "             11: ['November', 'Fall'],\n",
      "             12: ['December', 'Winter']}\n",
      "\n",
      "# Maps the data as a month\n",
      "raw_map['COLLECTION_MONTH'] = \\\n",
      "    raw_map.COLLECTION_DATE.apply(lambda x:month_map[x.month][0])\n",
      "\n",
      "# Maps the data as a season\n",
      "raw_map['COLLECTION_SEASON'] = \\\n",
      "    raw_map.COLLECTION_DATE.apply(lambda x:month_map[x.month][1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"map_loc\"></a>\n",
      "### Collection Location\n",
      "[Location map text 1]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Removes state information for any state not in the US\n",
      "# (This may change as additional countries are added.)\n",
      "countries = raw_map.groupby('COUNTRY').count().STATE.index.values\n",
      "for country in countries:\n",
      "    if country not in {'GAZ:United States of America', 'GAZ:Canada'}:\n",
      "        raw_map.loc[raw_map.COUNTRY == country, 'STATE'] = np.nan\n",
      "\n",
      "# Handles regional mapping, cleaning up states so that only American and\n",
      "# Canadian states are included \n",
      "def check_state(x):\n",
      "    if isinstance(x, str) and x in us_state_map:\n",
      "        return us_state_map[x.upper()]\n",
      "    elif  isinstance(x, str) and x in canadian_map_english:\n",
      "        return canadian_map_english[x.upper()]\n",
      "    else:\n",
      "        return np.nan\n",
      "raw_map['STATE'] = raw_map.STATE.apply(check_state)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Region binning text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Bins data by census region\n",
      "def census_f(x):\n",
      "    if  isinstance(x, str) and x in regions_by_state:\n",
      "        return regions_by_state[x]['Census_1']\n",
      "    else:\n",
      "        return np.nan\n",
      "raw_map['CENSUS_REGION'] = raw_map.STATE.apply(census_f)\n",
      "\n",
      "\n",
      "# Bins data by economic region\n",
      "def economic_f(x):\n",
      "    if isinstance(x, str) and  x in regions_by_state:\n",
      "        return regions_by_state[x]['Economic']\n",
      "    else:\n",
      "        return np.nan\n",
      "raw_map['ECONOMIC_REGION'] = raw_map.STATE.apply(economic_f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"map_sleep\"></a>\n",
      "### Sleep Duration\n",
      "[sleep map text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "raw_map.loc[raw_map.SLEEP_DURATION == 'Less than 5 hours', 'SLEEP_DURATION'] = 'Less than 6 hours'\n",
      "raw_map.loc[raw_map.SLEEP_DURATION == '5-6 hours', 'SLEEP_DURATION'] = 'Less than 6 hours'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 28
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"subset\"></a>\n",
      "## Identification of a Healthy Subset of Adults\n",
      "[Healthy subset text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Reads in the mapping file\n",
      "if 'SUBSET' not in raw_map.columns:\n",
      "    subset_f = {'AGE': lambda x: 19 < x < 70 and not np.isnan(x),\n",
      "                'DIABETES': lambda x: x == 'I do not have diabetes',\n",
      "                'IBD': lambda x: x == 'I do not have IBD',\n",
      "                'ANTIBIOTIC_SELECT': lambda x: x == 'Not in the last year',\n",
      "                'BMI': lambda x: 18.5 <= x < 30 and not np.isnan(x)}\n",
      "\n",
      "    # Determines which samples meet the requirements of the categories\n",
      "    new_bin = {}\n",
      "    for cat, f in subset_f.iteritems():\n",
      "        new_bin[cat] = raw_map[cat].apply(f)\n",
      "\n",
      "    # Builds up the new binary dataframe\n",
      "    bin_frame = pd.DataFrame(new_bin)\n",
      "\n",
      "    # Adds a column to the current dataframe to look at the subset\n",
      "    bin_series = pd.DataFrame(new_bin).all(1)\n",
      "    bin_series.name = 'SUBSET'\n",
      "\n",
      "    raw_map = raw_map.join(bin_series)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"rare\"></a>\n",
      "## Whole Table Rarefaction\n",
      "[Rarefaction text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if not os.path.exists(os.path.join(rare_dir, rare_pattern \n",
      "                                   % (rarefaction_depth, (num_rarefactions-1)))) or overwrite:\n",
      "    !multiple_rarefactions_even_depth.py -i $download_otu_fp -o $rare_dir -n $num_rarefactions -d $rarefaction_depth --lineages_included"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "<a id=\"alpha\"></a>\n",
      "## Whole Table Alpha Diversity\n",
      "[alpha diversity text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if not os.path.exists(os.path.join(alpha_dir, alpha_pattern\n",
      "                                   % (rarefaction_depth, (num_rarefactions-1)))) or overwrite:\n",
      "    !alpha_diversity.py -i $rare_dir -o $alpha_dir -m $alpha_metrics -t $tree_fp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[more alpha text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Prealocates an output object for alpha diversity\n",
      "alpha_rounds = {'%s' % m: {} for m in alpha_metrics.split(',')}\n",
      "div_metric = alpha_metrics.split(',')[0]\n",
      "\n",
      "# Loops through the rarefaction instances\n",
      "for ri in range(num_rarefactions):\n",
      "    \n",
      "    # Sets the alpha diveristy filepath\n",
      "    alpha_fp = os.path.join(alpha_dir, alpha_pattern) % (rarefaction_depth, ri)\n",
      "    # Loads the alpha diveristy table\n",
      "    alpha = pd.read_csv(alpha_fp,\n",
      "                        sep=txt_delim,\n",
      "                        index_col=False)\n",
      "    alpha.index = alpha['Unnamed: 0']\n",
      "    del alpha['Unnamed: 0']\n",
      "    \n",
      "    # Extracts the alpha diversity metrics\n",
      "    for col in alpha_rounds:\n",
      "        alpha_rounds[col]['%i' %ri] = alpha[col]\n",
      "        alpha_rounds[col]['%i' %ri].name = '%i' % ri"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Complies the alpha diversity results into a single table\n",
      "alpha_df = pd.DataFrame({'%s_mean' % metric: pd.DataFrame(alpha_rounds[metric]).mean(1)\n",
      "                         for metric in alpha_metrics.split(',')})\n",
      "\n",
      "# Adds the alpha diversity results to the rarefied table\n",
      "rare_map = raw_map.copy()\n",
      "rare_map = rare_map.join(alpha_df)\n",
      "rare_check = np.isnan(rare_map['%s_mean' % div_metric]) == False\n",
      "rare_map = rare_map.loc[rare_check]\n",
      "\n",
      "# Draws the data assoicated with each of the alpha diveristy rounds\n",
      "all_rounds = pd.DataFrame(alpha_rounds[div_metric])\n",
      "\n",
      "# Lines up the data so the indices match (as a precaution)\n",
      "all_rounds = all_rounds.sort_index()\n",
      "alpha_df = alpha_df.sort_index()\n",
      "\n",
      "# Calculates the distance between each round and the mean\n",
      "mean_rounds = ([alpha_df['%s_mean' % div_metric].values] * \n",
      "               np.ones((num_rarefactions, 1))).transpose()\n",
      "diff = np.sqrt(np.square(all_rounds.values - np.square(mean_rounds))) / mean_rounds\n",
      "\n",
      "# Determines the minimum distance between the round and the mean\n",
      "round_labels = np.arange(0, 10)\n",
      "round_avg = diff.mean(0)\n",
      "\n",
      "best_rarefaction = round_labels[round_avg == min(round_avg)][0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[all sample table text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Saves the unrarefied mapping file\n",
      "raw_map.to_csv(os.path.join(all_dir, map_fn) % (all_, all_, raw_suffix),\n",
      "               sep=txt_delim,\n",
      "               na_rep=write_na,\n",
      "               index_label=map_index)\n",
      "\n",
      "# Saves the rarefied mapping file\n",
      "rare_map.to_csv(os.path.join(all_dir, map_fn) % (all_, all_, rare_suffix),\n",
      "               sep=txt_delim,\n",
      "               na_rep=write_na,\n",
      "               index_label=map_index)\n",
      "\n",
      "# Copies the raw OTU table\n",
      "shutil.copy2(download_otu_fp, \n",
      "             os.path.join(all_dir, otu_fn) % (all_, all_, raw_suffix))\n",
      "\n",
      "# Copies the rarefied OTU table\n",
      "shutil.copy2(os.path.join(rare_dir, rare_pattern) % (rarefaction_depth, best_rarefaction),\n",
      "             os.path.join(all_dir, otu_fn) % (all_, all_, rare_suffix))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "<a id=\"beta\"></a>\n",
      "## Whole Table Beta Diversity\n",
      "[beta diversity text 1]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sets up the filepaths for the all sample raried table\n",
      "all_otu_rare_fp = os.path.join(all_dir, otu_fn) % (all_, all_, rare_suffix)\n",
      "all_uud_rare_fp = os.path.join(all_dir, uud_fn) % (all_, all_, rare_suffix)\n",
      "all_wud_rare_fp = os.path.join(all_dir, wud_fn) % (all_, all_, rare_suffix)\n",
      "\n",
      "# Calculates the beta diversity\n",
      "if not (os.path.exists(all_uud_rare_fp) and \n",
      "        os.path.exists(all_wud_rare_fp)) or overwrite:\n",
      "    !beta_diversity.py -i $all_otu_rare_fp -m $beta_metrics -t $tree_fp -o $all_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Reutrn to the top</a>\n",
      "\n",
      "<a id=\"split\"></a>\n",
      "## Split the table by bodysite\n",
      "[Split by bodysite text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sets the raw location file names\n",
      "all_raw_otu_fp = os.path.join(all_dir, otu_fn) % (all_, all_, raw_suffix)\n",
      "all_raw_map_fp = os.path.join(all_dir, map_fn) % (all_, all_, raw_suffix)\n",
      "\n",
      "# Sets the rarefied location file names\n",
      "all_rare_otu_fp = os.path.join(all_dir, otu_fn) % (all_, all_, rare_suffix)\n",
      "all_rare_map_fp = os.path.join(all_dir, map_fn) % (all_, all_, rare_suffix)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Checks that the raw and rarified bodysite split tables exist\n",
      "raw_split_check = np.array([])\n",
      "rare_split_check = np.array([])\n",
      "for site in all_bodysites:\n",
      "    raw_otu_exist = os.path.exists(os.path.join(split_raw_dir, split_fn) \n",
      "                                   % (raw_suffix, split_field, \n",
      "                                      split_prefix, site, otu_ft))\n",
      "    raw_map_exist = os.path.exists(os.path.join(split_raw_dir, split_fn) \n",
      "                                   % (raw_suffix, split_field, \n",
      "                                      split_prefix, site, map_ft))\n",
      "    raw_split_check = np.hstack((raw_split_check, raw_otu_exist, raw_map_exist))\n",
      "    \n",
      "    rare_otu_exist = os.path.exists(os.path.join(split_rare_dir, split_fn) \n",
      "                                   % (rare_suffix, split_field, \n",
      "                                      split_prefix, site, otu_ft))\n",
      "    rare_map_exist = os.path.exists(os.path.join(split_rare_dir, split_fn) \n",
      "                                   % (rare_suffix, split_field, \n",
      "                                      split_prefix, site, map_ft))\n",
      "    rare_split_check = np.hstack((rare_split_check, rare_otu_exist, rare_map_exist))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Splits the otu table and mapping file by bodysite\n",
      "if not raw_split_check.any():\n",
      "    !split_otu_table.py -i $all_raw_otu_fp -m $all_raw_map_fp -f BODY_HABITAT -o $split_raw_dir \n",
      "\n",
      "# Splits the otu table and mapping file by bodysite\n",
      "if not rare_split_check.any():\n",
      "    !split_otu_table.py -i $all_rare_otu_fp -m $all_rare_map_fp -f BODY_HABITAT -o $split_rare_dir "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 38
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Happy filler save text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Copies the files to their correct final folder\n",
      "for idx, h_site in enumerate(habitat_sites):\n",
      "    a_site = all_bodysites[idx]\n",
      "    # Copies the unrarefied mapping file\n",
      "    shutil.copy2(os.path.join(split_raw_dir, split_fn) \n",
      "                 % (raw_suffix, split_field, split_prefix, h_site, map_ft),\n",
      "                 os.path.join(asab_pattern, map_fn) \n",
      "                 % (a_site, raw_suffix, site_pad, a_site))\n",
      "\n",
      "    # Copies the unrarefied OTU table\n",
      "    shutil.copy2(os.path.join(split_raw_dir, split_fn) \n",
      "                 % (raw_suffix, split_field, split_prefix, h_site, otu_ft),\n",
      "                 os.path.join(asab_pattern, otu_fn) \n",
      "                 % (a_site, raw_suffix, site_pad, a_site))\n",
      "\n",
      "    # Copies the rarefied mapping file\n",
      "    shutil.copy2(os.path.join(split_rare_dir, split_fn) \n",
      "                 % (rare_suffix, split_field, split_prefix, h_site, map_ft),\n",
      "                 os.path.join(asab_pattern, map_fn) \n",
      "                 % (a_site, rare_suffix, site_pad, a_site))\n",
      "\n",
      "    # Copies the rarefied OTU table\n",
      "    shutil.copy2(os.path.join(split_rare_dir, split_fn) \n",
      "                 % (rare_suffix, split_field, split_prefix, h_site, otu_ft),\n",
      "                 os.path.join(asab_pattern, otu_fn)\n",
      "                 % (a_site, rare_suffix, site_pad, a_site))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 39
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Filtering explination text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for idx, h_site in enumerate(habitat_sites):\n",
      "    # Gets the all site body site\n",
      "    a_site = all_bodysites[idx]\n",
      "    \n",
      "    # Gets the rarefied mapping file for the site\n",
      "    map_in = os.path.join(asab_pattern, map_fn)  % (a_site, rare_suffix, site_pad, a_site)\n",
      "\n",
      "    # Sets up the unweighed filenames\n",
      "    uud_dm_in = os.path.join(all_dir, uud_fn) % (rare_suffix, all_, all_)\n",
      "    uud_dm_out = os.path.join(asab_pattern, uud_fn) % (a_site, rare_suffix, site_pad, a_site)\n",
      "\n",
      "    # Sets up the weighted filenames\n",
      "    wud_dm_in = os.path.join(all_dir, wud_fn) % (rare_suffix, all_, all_)\n",
      "    wud_dm_out = os.path.join(asab_pattern, wud_fn) % (a_site, rare_suffix, site_pad, a_site)\n",
      "    \n",
      "    # Filters the unweighted distance matrix\n",
      "    if not os.path.exists(uud_dm_out) or overwrite:\n",
      "        !filter_distance_matrix.py -i $uud_dm_in -o $uud_dm_out --sample_id_fp $map_in\n",
      "    \n",
      "    # Filters the weighted distance matrix\n",
      "    if not os.path.exists(wud_dm_out) or overwrite:\n",
      "        !filter_distance_matrix.py -i $wud_dm_in -o $wud_dm_out --sample_id_fp $map_in"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"single\"></a>\n",
      "## Select a Single Sample for Each Participant\n",
      "[Single Sample]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def identify_single_samples(map_):\n",
      "    \"\"\"Selects a single sample for each participant\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    map_ : pandas DataFrame\n",
      "        A mapping file for our set of samples. A single body site should be\n",
      "        used with human samples.\n",
      "\n",
      "    Returns\n",
      "    -------\n",
      "    single_ids : ndarray\n",
      "        A list of ids which represent a single sample per individual\n",
      "\n",
      "    \"\"\"\n",
      "\n",
      "    # Prealocates a single sample array\n",
      "    single_ids = np.array([])\n",
      "\n",
      "    # Identifies a single sample per individual\n",
      "    for indv, ids in map_.groupby('HOST_SUBJECT_ID').groups.iteritems():\n",
      "        single_ids = np.hstack((single_ids, \n",
      "                                np.random.choice(np.array(ids, dtype=str), 1)))\n",
      "\n",
      "    return single_ids"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "[Description of filtering]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for a_site in all_bodysites:\n",
      "    # Skips any site not suggested in our list\n",
      "    if a_site not in one_samp_sites:\n",
      "        continue\n",
      "    # Sets up names for the all sample files\n",
      "    sample_spaces = (a_site, rare_suffix, site_pad, a_site)\n",
      "    site_map_fp = os.path.join(asab_pattern, map_fn) % sample_spaces\n",
      "    site_otu_fp = os.path.join(asab_pattern, otu_fn) % sample_spaces\n",
      "    site_uud_fp = os.path.join(asab_pattern, uud_fn) % sample_spaces\n",
      "    site_wud_fp = os.path.join(asab_pattern, wud_fn) % sample_spaces\n",
      "\n",
      "    # Sets up names for the single sample files\n",
      "    sin_site_map_fp = os.path.join(assb_pattern, map_fn) % sample_spaces\n",
      "    sin_site_otu_fp = os.path.join(assb_pattern, otu_fn) % sample_spaces\n",
      "    sin_site_uud_fp = os.path.join(assb_pattern, uud_fn) % sample_spaces\n",
      "    sin_site_wud_fp = os.path.join(assb_pattern, wud_fn) % sample_spaces\n",
      "    sin_site_ids_fp = os.path.join(assb_pattern, ss_fn) % a_site\n",
      "\n",
      "    if overwrite or not (os.path.exists(sin_site_ids_fp) and \n",
      "                         os.path.exists(sin_site_map_fp)):\n",
      "        # Reads in the rarefied table specific to the body site\n",
      "        site_map = pad_index(pd.read_csv(site_map_fp,\n",
      "                                         sep=txt_delim, \n",
      "                                         na_values=map_nas,\n",
      "                                         index_col=False,\n",
      "                                         parse_dates=date_cols,\n",
      "                                         infer_datetime_format=True),\n",
      "                             index_col=map_index)\n",
      "        # Filters the OTU table down to single samples\n",
      "        site_otu = load_table(site_otu_fp)\n",
      "\n",
      "        # Filters the table so only the samples that are present in both tables are considered\n",
      "        site_map = site_map.loc[site_otu.ids(axis='sample')]\n",
      "\n",
      "        # Selects single sample ids\n",
      "        single_site_ids = identify_single_samples(site_map)\n",
      "\n",
      "        # Saves the single ids file\n",
      "        sin_ids_file = file(sin_site_ids_fp, 'w')\n",
      "        sin_ids_file.write('\\n'.join(list(single_site_ids)))\n",
      "        sin_ids_file.close()\n",
      "\n",
      "        # Gets the single sample per participant body site map\n",
      "        single_site_map = site_map.loc[single_site_ids]\n",
      "        single_site_otu = site_otu.filter(single_site_ids, axis='sample')\n",
      "\n",
      "        # Saves the single sample map\n",
      "        single_site_map.to_csv(sin_site_map_fp,\n",
      "                               sep=txt_delim,\n",
      "                               na_rep=write_na,\n",
      "                               index_label=map_index)\n",
      "\n",
      "    # Filters the OTU table down to single samples\n",
      "    if not os.path.exists(sin_site_otu_fp) or overwrite:\n",
      "        !biom subset-table -i $site_otu_fp -o $sin_site_otu_fp -a sample -s $sin_site_ids_fp\n",
      "        \n",
      "    # Filters the distance matrices\n",
      "    if not os.path.exists(sin_site_uud_fp) or overwrite:\n",
      "        !filter_distance_matrix.py -i $site_uud_fp -o $sin_site_uud_fp --sample_id_fp $sin_site_ids_fp\n",
      "    if not os.path.exists(sin_site_wud_fp) or overwrite:\n",
      "        !filter_distance_matrix.py -i $site_wud_fp -o $sin_site_wud_fp --sample_id_fp $sin_site_ids_fp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"filt_subset\"></a>\n",
      "## Filter the healthy sample subset\n",
      "[Healthy sample text!]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for a_site in all_bodysites:\n",
      "    # Skips any site where the healthy subset criteria should not be applied\n",
      "    if a_site not in sub_part_sites:\n",
      "        continue\n",
      "    \n",
      "    # Sets up the filepaths for import and starting files\n",
      "    sample_spaces = (a_site, rare_suffix, site_pad, a_site)\n",
      "    all_map_fp = os.path.join(asab_pattern, map_fn) % sample_spaces\n",
      "    all_otu_fp = os.path.join(asab_pattern, otu_fn) % sample_spaces\n",
      "    all_uud_fp = os.path.join(asab_pattern, uud_fn) % sample_spaces\n",
      "    all_wud_fp = os.path.join(asab_pattern, wud_fn) % sample_spaces    \n",
      "    \n",
      "    # Sets up the file paths for file returns\n",
      "    sub_map_fp = os.path.join(ssab_pattern, map_fn) % sample_spaces\n",
      "    sub_otu_fp = os.path.join(ssab_pattern, otu_fn) % sample_spaces\n",
      "    sub_uud_fp = os.path.join(ssab_pattern, uud_fn) % sample_spaces\n",
      "    sub_wud_fp = os.path.join(ssab_pattern, wud_fn) % sample_spaces  \n",
      "    sub_ids_fp = os.path.join(ssab_pattern, sub_fn) % a_site\n",
      "            \n",
      "    # We'll start by generating a list of the subset of samples\n",
      "    if overwrite or not (os.path.exists(sub_ids_fp) and \n",
      "                          os.path.exists(sub_map_fp)):\n",
      "        # Loads the all sample mapping file\n",
      "        all_map = pad_index(pd.read_csv(all_map_fp,\n",
      "                                        sep=txt_delim, \n",
      "                                        na_values=map_nas,\n",
      "                                        index_col=False,\n",
      "                                        parse_dates=date_cols,\n",
      "                                        infer_datetime_format=True),\n",
      "                            index_col=map_index)\n",
      "        # Filters the table for the healthy subset of ids\n",
      "        sub_map = all_map.loc[all_map.SUBSET]\n",
      "        \n",
      "        # Gets the list of ids associted with the healthy subset\n",
      "        subset_ids = sub_map.index.values\n",
      "                \n",
      "        # Saves the healthy subset list of ids\n",
      "        sub_ids_file = file(sub_ids_fp, 'w')\n",
      "        sub_ids_file.write('\\n'.join(list(subset_ids)))\n",
      "        sub_ids_file.close()\n",
      "        \n",
      "        sub_map.to_csv(sub_map_fp,\n",
      "                       sep=txt_delim,\n",
      "                       na_rep=write_na,\n",
      "                       index_label=map_index)\n",
      "        \n",
      "    # Filters the OTU table\n",
      "    if not os.path.exists(sub_otu_fp) or overwrite:\n",
      "        !biom subset-table -i $all_otu_fp -o $sub_otu_fp -a sample -s $sub_ids_fp\n",
      "        \n",
      "    # Filters the distance matrices\n",
      "    if not os.path.exists(sub_uud_fp) or overwrite:\n",
      "        !filter_distance_matrix.py -i $all_uud_fp -o $sub_uud_fp --sample_id_fp $sub_ids_fp\n",
      "    if not os.path.exists(sub_wud_fp) or overwrite:\n",
      "        !filter_distance_matrix.py -i $all_wud_fp -o $sub_wud_fp --sample_id_fp $sub_ids_fp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for a_site in all_bodysites:\n",
      "    # Skips any site where the healthy subset criteria should not be applied\n",
      "    if a_site not in sub_part_sites or a_site not in one_samp_sites:\n",
      "        continue\n",
      "    \n",
      "    # Sets up the filepaths for import and starting files\n",
      "    sample_spaces = (a_site, rare_suffix, site_pad, a_site)\n",
      "    all_map_fp = os.path.join(assb_pattern, map_fn) % sample_spaces\n",
      "    all_otu_fp = os.path.join(assb_pattern, otu_fn) % sample_spaces\n",
      "    all_uud_fp = os.path.join(assb_pattern, uud_fn) % sample_spaces\n",
      "    all_wud_fp = os.path.join(assb_pattern, wud_fn) % sample_spaces    \n",
      "    \n",
      "    # Sets up the file paths for file returns\n",
      "    sub_map_fp = os.path.join(sssb_pattern, map_fn) % sample_spaces\n",
      "    sub_otu_fp = os.path.join(sssb_pattern, otu_fn) % sample_spaces\n",
      "    sub_uud_fp = os.path.join(sssb_pattern, uud_fn) % sample_spaces\n",
      "    sub_wud_fp = os.path.join(sssb_pattern, wud_fn) % sample_spaces  \n",
      "    sub_ids_fp = os.path.join(sssb_pattern, sub_fn) % a_site\n",
      "            \n",
      "    # We'll start by generating a list of the subset of samples\n",
      "    if overwrite or not (os.path.exists(sub_ids_fp) and \n",
      "                          os.path.exists(sub_map_fp)):\n",
      "        # Loads the all sample mapping file\n",
      "        all_map = pad_index(pd.read_csv(all_map_fp,\n",
      "                                        sep=txt_delim, \n",
      "                                        na_values=map_nas,\n",
      "                                        index_col=False,\n",
      "                                        parse_dates=date_cols,\n",
      "                                        infer_datetime_format=True),\n",
      "                            index_col=map_index)\n",
      "        # Filters the table for the healthy subset of ids\n",
      "        sub_map = all_map.loc[all_map.SUBSET]\n",
      "        \n",
      "        # Gets the list of ids associted with the healthy subset\n",
      "        subset_ids = sub_map.index.values\n",
      "                \n",
      "        # Saves the healthy subset list of ids\n",
      "        sub_ids_file = file(sub_ids_fp, 'w')\n",
      "        sub_ids_file.write('\\n'.join(list(subset_ids)))\n",
      "        sub_ids_file.close()\n",
      "        \n",
      "        sub_map.to_csv(sub_map_fp,\n",
      "                       sep=txt_delim,\n",
      "                       na_rep=write_na,\n",
      "                       index_label=map_index)\n",
      "        \n",
      "    # Filters the OTU table\n",
      "    if not os.path.exists(sub_otu_fp) or overwrite:\n",
      "        !biom subset-table -i $all_otu_fp -o $sub_otu_fp -a sample -s $sub_ids_fp\n",
      "        \n",
      "    # Filters the distance matrices\n",
      "    if not os.path.exists(sub_uud_fp) or overwrite:\n",
      "        !filter_distance_matrix.py -i $all_uud_fp -o $sub_uud_fp --sample_id_fp $sub_ids_fp\n",
      "    if not os.path.exists(sub_wud_fp) or overwrite:\n",
      "        !filter_distance_matrix.py -i $all_wud_fp -o $sub_wud_fp --sample_id_fp $sub_ids_fp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "[Conclusion text]"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
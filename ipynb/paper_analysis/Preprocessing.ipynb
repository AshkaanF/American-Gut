{
 "metadata": {
  "name": "",
  "signature": "sha256:439ef06b555dfd6efb5a9f20db82811ec393e0b29f02c3affe676ae61da53da7"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This notebook will preform pre-processing necessary for American Gut Analysis. It is recommended this notebook be used before subsequent, individual analysis notebooks (<a href=\"\">i.e. 2.Rarefaction</a>). This notebook will generate tables necessary to run the subsequent notebooks. It does not need to be run again, unless a new OTU tables have been acquired.\n",
      "\n",
      "If you choose not to run this notebook, all the OTU tables generated here can be downloaded in a tar file from link. Individual data sets can be found\n",
      "<ul><li>All OTUs, all samples\n",
      "</li><li>Filtered OTUs, all samples\n",
      "</li><li>All OTUs, single sample per individual\n",
      "</li><li>Filtered OTUs, single sample per individual\n",
      "</li><li>All OTUs, \n",
      "\n",
      "This notebook assumes the following system requirements.\n",
      "<ul><li><a href=\"https://www.python.org/download/releases/2.7/\">Python 2.7</a>\n",
      "</li><li><a href=\"https://pypi.python.org/pypi/numpy\">Numpy $\\geq$ 1.7</a>\n",
      "</li><li><a href=\"http://qiime.org/install/install.html#latest-development-version\">Qiime 1.8 (development version), commit </a>\n",
      "</li><li><a href=\"http://biom-format.org\">Biom 2.0.1</a>\n",
      "</li><li><a href=\"http://scikit-bio.org\">Scikit Bio 0.1.4</a>\n",
      "</li><li><a href=\"http://pandas.pydata.org\">Pandas 0.14.1</a>\n",
      "</li><li><a href=\"http://ipython.org\">iPython</a>\n",
      "</li></ul>\n",
      "\n",
      "<a id=\"top\"></a>\n",
      "###Table of Contents\n",
      "<ul><li><a href=\"#parameters\">Sets up parameters for data analysis</a>\n",
      "</li><li><a href=\"#files\">Set up files and directories for analysis</a>\n",
      "</li><li><a href=\"#github_download\">Download raw OTU tables from GitHub</a>. This will require an internet connection.\n",
      "</li><li><a href=\"#splitsite\">Split the OTU tables by bodysite.</a>\n",
      "</li><li><a href=\"#clean_map\">Cleans the mapping columns file.</a>\n",
      "</li><li>The mapping file is updated to include a set of derived columns.\n",
      "<ul><li><a href=\"#age_bin\">Age</a>\n",
      "</li><li><a href=\"#etoh_bin\">Alcohol Consumption</a>\n",
      "</li><li><a href=\"#bmi_bin\">BMI</a>\n",
      "</li><li><a href=\"#month_bin\">Collection Date</a>\n",
      "</li><li><a href=\"#state_bin\">Collection Location</a>\n",
      "</li></ul>\n",
      "</li><li><a href=\"#id_subset\">Identifies the subetset of the data</a>\n",
      "</li><li><a href=\"#filter\">Filters the data to remove uncommon OTUs</a>\n",
      "</li><li><a href=\"#rarefaction\">Rarefies the data</a>\n",
      "</li><li><a href=\"#alpha\">Calculates the alpha diversity</a>\n",
      "</li><li><a href=\"#single\">Identifies single sample OTU table and mapping file</a>\n",
      "</li><li><a href=\"#beta\">Calculates beta diversity for the tables</a>\n",
      "</li></ul>\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Imports necessary functions\n",
      "from os import mkdir, remove\n",
      "from os.path import abspath, join as pjoin, exists, split\n",
      "from shutil import copy2, move\n",
      "from numpy import (nan, isnan, arange, ones, sqrt, \n",
      "                   square, nanmin, hstack, array, ceil)\n",
      "from numpy.random import choice\n",
      "from pandas import read_csv, Series, DataFrame\n",
      "from biom import load_table\n",
      "from skbio import DistanceMatrix\n",
      "from jwd_code.pandas_fun import check_dir, pad_index, check_strs\n",
      "from jwd_code.geography_lib import (regions_by_state,\n",
      "                                    us_state_map,\n",
      "                                    canadian_map_english)\n",
      "\n",
      "# Writes a file to save the json string tables\n",
      "def write_biom(table, fp):\n",
      "    \"\"\"Writes a biom table as a json string\"\"\"\n",
      "    file_ = open(fp, 'w')\n",
      "    file_.write(table.to_json(''))\n",
      "    file_.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/Users/jwdebelius/.virtualenvs/qiime_dev/lib/python2.7/site-packages/matplotlib/__init__.py:1155: UserWarning:  This call to matplotlib.use() has no effect\n",
        "because the backend has already been chosen;\n",
        "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
        "or matplotlib.backends is imported for the first time.\n",
        "\n",
        "  warnings.warn(_use_error_msg)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "<a id=\"parameters\"></a>\n",
      "### Sets Analysis Parameters\n",
      "\n",
      "We need to consider several parameters. These will handle the file reading, rarefaction, alpha_diversity and beta_diversity handling.\n",
      "\n",
      "We can start by setting an important intial parameter: <strong><code>overwrite</code></strong>. This allows us to determin if files files should be downloaded and processed or not. To minimize computational time, <code>overwrite</code> should be <code><font color=\"green\">False</font></code> unless downloading new tables.\n",
      "\n",
      "##### Pandas filehandling parameters\n",
      "<ul><li>The <strong><code>txt_delim</code></strong> specifies the way columns are seperated in the files. Qiime standards typically use text (<code>.txt</code>) files, which are seperated by a tab-character (<code><font color=\"FireBrick\">'\\t'</font></code>).\n",
      "</li><li><strong><code>map_index</code></strong> specifies the name of the file containing the sample names. In Qiime, this is named #SampleID.\n",
      "</li><li>Possible empty values, <strong><code>map_nas</code></strong> provides a list of values which specify data has not been supplied. American Gut participants are free to skip any survey question they do not wish to answer. As a result, the mapping file can contain  empty or missing-data fields.\n",
      "</li><li><strong><code>write_na</code></strong> gives a value used when the files are written. Using an empty space, <code><font color=\"FireBrick\">''</font></code>, scripts like <code>group_signifigance.py</code> will ignore the group.\n",
      "</li></ul>\n",
      "\n",
      "##### Rarefaction parameters\n",
      "<ul><li>The <strong><code>rarefaction_depth</code></strong> specifies the number of sequence per samples to be used for analysis. A depth of 10,000 seqs/sample was selected  because it balances a better picture of diversity with retaining samples. Rarefaction begins by removing samples from the table which do not have the minimum number of counts. Sequences are then drawn randomly out of a weighted pool until we reach the appropriate number. Our unpublished data shows rarefaction is conservative and is appropriate for UniFrac measurements.\n",
      "</li><li><strong><code>num_rarifactions</code></strong> gives the number of rarefaction instances which should be drawn. This controls for bias due to single rarefaction instances. We selected 10 rarefactions to achieve a balance between computational effeciency and appropriate depth.\n",
      "</li></ul>\n",
      "\n",
      "##### Filtering parameters\n",
      "The filtering parameters, <strong><code>filt_frac</code></strong> and <strong><code>filt_num</code></strong> refer to the minimum number of samples, or the minimum fraction of samples in which a particular OTU must be present to be retained after filtering. This final filtering fraction is calculated as the minimum of these two numbers.\n",
      "\n",
      "##### Aphha Diversity Metrics\n",
      "<ul><li><strong><code>alpha_metrics</code></strong> is a comma-seperated string, listing the desired metrics. <br>The current notebook is set to calculate four alpha diversity metrics, <em>PD Whole Tree</em>, <em>Observed Species</em>, <em>choa1</em> and <em>shannon</em> diveristy. A list of avaliable metrics can be found through the <a href=\"http://scikit-bio.org/docs/latest/generated/skbio.diversity.alpha.html#module-skbio.diversity.alpha\">Scikit-Bio website</a>.\n",
      "</li><li><strong><code>div_metric</code></strong> is the diversity metric to be used during analysis.<br>While we can calculate a variety of diversity metrics, is advantegous to focus only on one metric during analysis. Here, we use the mean of the 10 PD whole tree diversity calculations, performed one each rarified table. PD whole tree diversity was selected for thsi analysis becuase it takes into account not only the number of different organisms present, but also their similarity and dissimilarity.\n",
      "</li></ul>\n",
      "\n",
      "##### Beta Diversity Metrics\n",
      "<ul><li><strong><code>beta_metrics</code></strong> are a list of beta diversity metrics. The default is to use weighted and unweighted UniFrac distance.\n",
      "</li></ul>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "overwrite = False\n",
      "\n",
      "# Sets up parameters for when pandas reads and writes data.\n",
      "txt_delim = '\\t'\n",
      "map_index = '#SampleID'\n",
      "map_nas = ['NA', 'no_data', 'unknown', '']\n",
      "write_na = ''\n",
      "\n",
      "# Sets up rarifaction parameter for 10,000 sequences/sample and \n",
      "# 10 rounds of rarifaction.\n",
      "rarifaction_depth = 10000\n",
      "num_rarifactions = 10\n",
      "\n",
      "# Sets the filtering parameters.\n",
      "filt_frac = 0.01\n",
      "filt_num = 50\n",
      "\n",
      "# Handles the alpha diversity metrics\n",
      "alpha_metrics = 'PD_whole_tree,observed_species,chao1,shannon'\n",
      "div_metric = 'PD_whole_tree'\n",
      "\n",
      "# Handles the beta diversity metrics\n",
      "beta_metrics = \"unweighted_unifrac,weighted_unifrac\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"files\"></a>\n",
      "#### Sets up files\n",
      "\n",
      "We can begin by setting up directories to save the files which will be downloaded and handled here. The default setting is to perform the analysis in a new directory, <code>AGPanalysis</code> in the parent directory of the current directory (assumed to be the notebook directory).\n",
      "\n",
      "To change where data is saved, the <code>base_dir</code> should be set.\n",
      "\n",
      "We can also set the filenames for saving data in the directory. We will produce eight sets of files:\n",
      "<ul><li>The unfiltered table with all samples\n",
      "</li><li>The filtered table, with all samples\n",
      "</li><li>The unfiltered table with only a subset of healhty individuals\n",
      "</li><li>The filtered table with only a subset of healhty individuals\n",
      "</li><li>The unfiltered table with a single sample per indidivual\n",
      "</li><li>The filtered table, with a single sample per indidivual\n",
      "</li><li>The unfiltered table with a single sample for each healthy indiviual\n",
      "</li><li>The filtered table with only a single sample for each healthy indiviual\n",
      "</li></ul>\n",
      " "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sets the base directory for the analysis\n",
      "base_dir = pjoin(abspath('..'), 'agp_analysis')\n",
      "check_dir(base_dir)\n",
      "\n",
      "# Sets up a directory for the OTU information\n",
      "otu_dir = pjoin(base_dir, \"otu_tables\")\n",
      "check_dir(otu_dir)\n",
      "\n",
      "# Creates a new directory where the raw OTU table and raw mapping file should be saved\n",
      "raw_dir = pjoin(otu_dir, 'raw_otu_tables')\n",
      "check_dir(raw_dir)\n",
      "\n",
      "# Creates a directory where split tables should be saved\n",
      "split_dir = pjoin(otu_dir, \"split_by_bodysite\")\n",
      "check_dir(split_dir)\n",
      "\n",
      "# Creates a directory for the the filtered data\n",
      "fecal_dir = pjoin(otu_dir, 'fecal_samples')\n",
      "check_dir(fecal_dir)\n",
      "\n",
      "# Sets up a directory for rarefaction\n",
      "raw_rare_dir = pjoin(otu_dir, \"raw_rarefaction\")\n",
      "check_dir(raw_rare_dir)\n",
      "filt_rare_dir = pjoin(otu_dir, \"filtered_rarefaction\")\n",
      "check_dir(filt_rare_dir)\n",
      "alpha_dir = pjoin(otu_dir, 'alpha')\n",
      "check_dir(alpha_dir)\n",
      "\n",
      "# Sets up directories for saving the tables, maps and distance matrices\n",
      "awt_dir = pjoin(base_dir, 'all_otus_all_samples')\n",
      "check_dir(awt_dir)\n",
      "ast_dir = pjoin(base_dir, 'all_otus_subset_samples')\n",
      "check_dir(ast_dir)\n",
      "aws_dir = pjoin(base_dir, 'all_otus_single_samples')\n",
      "check_dir(aws_dir)\n",
      "ass_dir = pjoin(base_dir, 'all_otus_subset_single_samples')\n",
      "check_dir(ass_dir)\n",
      "fwt_dir = pjoin(base_dir, 'filtered_otus_all_samples')\n",
      "check_dir(fwt_dir)\n",
      "fst_dir = pjoin(base_dir, 'filtered_otus_subset_samples')\n",
      "check_dir(fst_dir)\n",
      "fws_dir = pjoin(base_dir, 'filtered_otus_single_samples')\n",
      "check_dir(fws_dir)\n",
      "fss_dir = pjoin(base_dir, 'filtered_otus_subset_single_samples')\n",
      "check_dir(fss_dir)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can also set the file names for the dowloaded files.\n",
      "\n",
      "The <code>tree_fp</code> specifies the location of the phylogenetic tree used for the dataset. American Gut data was picked closed reference using 97% similarity in hte the greengenes 13_5 reference set. The reference set can be downloaded <a href=\"\">here</a>. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sets the reference tree filepath. This is required when using phylogentic\n",
      "# metrics such as PD_whole_tree alpha diversity and UniFrac beta diversity.\n",
      "tree_fp = '~/lib/Greengenes/gg_13_5_otus/trees/97_otus.tree'\n",
      "\n",
      "# Sets up the location filepaths for the raw data\n",
      "raw_otu_zip = pjoin(raw_dir, 'AG_100nt.biom.gz')\n",
      "raw_otu_fp = pjoin(raw_dir, 'AG_100nt.biom')\n",
      "raw_map_fp = pjoin(raw_dir, 'AG_100nt.txt')\n",
      "\n",
      "# Handles renaming the split files\n",
      "ori_feces_otu_fp = pjoin(split_dir, 'AG_100nt_UBERON:feces.biom')\n",
      "ori_feces_map_fp = pjoin(split_dir, 'mapping_UBERON:feces.txt')\n",
      "\n",
      "# Sets the filename pattern which will appear for the rarified table\n",
      "rare_filepattern = 'rarefaction_%i_%i.biom'\n",
      "\n",
      "# Sets up the alpha diversity filepattern\n",
      "alpha_filepattern = 'alpha_%s_even%i_%i.txt'\n",
      "\n",
      "# Sets the filepaths for the unrarified tables\n",
      "awtu_otu_fp = pjoin(awt_dir, 'AGP_100nt_fecal.biom')\n",
      "awtu_map_fp = pjoin(awt_dir, 'AGP_100nt_fecal.txt')\n",
      "astu_otu_fp = pjoin(ast_dir, 'AGP_100nt_fecal.biom')\n",
      "astu_map_fp = pjoin(ast_dir, 'AGP_100nt_fecal.txt')\n",
      "awsu_otu_fp = pjoin(aws_dir, 'AGP_100nt_fecal.biom')\n",
      "awsu_map_fp = pjoin(aws_dir, 'AGP_100nt_fecal.txt')\n",
      "assu_otu_fp = pjoin(ass_dir, 'AGP_100nt_fecal.biom')\n",
      "assu_map_fp = pjoin(ass_dir, 'AGP_100nt_fecal.txt')\n",
      "fwtu_otu_fp = pjoin(fwt_dir, 'AGP_100nt_fecal.txt')\n",
      "fwtu_map_fp = pjoin(fwt_dir, 'AGP_100nt_fecal.biom')\n",
      "fstu_otu_fp = pjoin(fst_dir, 'AGP_100nt_fecal.txt')\n",
      "fstu_map_fp = pjoin(fst_dir, 'AGP_100nt_fecal.biom')\n",
      "fwsu_otu_fp = pjoin(fws_dir, 'AGP_100nt_fecal.txt')\n",
      "fwsu_map_fp = pjoin(fws_dir, 'AGP_100nt_fecal.biom')\n",
      "fssu_otu_fp = pjoin(fss_dir, 'AGP_100nt_fecal.txt')\n",
      "fssu_map_fp = pjoin(fss_dir, 'AGP_100nt_fecal.biom')\n",
      "\n",
      "# Sets the filepath for the rarefied table\n",
      "awtr_otu_fp = pjoin(awt_dir, 'AGP_100nt_fecal_even10k.biom')\n",
      "awtr_map_fp = pjoin(awt_dir, 'AGP_100nt_fecal_even10k.txt')\n",
      "astr_otu_fp = pjoin(ast_dir, 'AGP_100nt_fecal_even10k.biom')\n",
      "astr_map_fp = pjoin(ast_dir, 'AGP_100nt_fecal_even10k.txt')\n",
      "awsr_otu_fp = pjoin(aws_dir, 'AGP_100nt_fecal_even10k.biom')\n",
      "awsr_map_fp = pjoin(aws_dir, 'AGP_100nt_fecal_even10k.txt')\n",
      "assr_otu_fp = pjoin(ass_dir, 'AGP_100nt_fecal_even10k.biom')\n",
      "assr_map_fp = pjoin(ass_dir, 'AGP_100nt_fecal_even10k.txt')\n",
      "fwtr_otu_fp = pjoin(fwt_dir, 'AGP_100nt_fecal_even10k.biom')\n",
      "fwtr_map_fp = pjoin(fwt_dir, 'AGP_100nt_fecal_even10k.txt')\n",
      "fstr_otu_fp = pjoin(fst_dir, 'AGP_100nt_fecal_even10k.biom')\n",
      "fstr_map_fp = pjoin(fst_dir, 'AGP_100nt_fecal_even10k.txt')\n",
      "fwsr_otu_fp = pjoin(fws_dir, 'AGP_100nt_fecal_even10k.biom')\n",
      "fwsr_map_fp = pjoin(fws_dir, 'AGP_100nt_fecal_even10k.txt')\n",
      "fssr_otu_fp = pjoin(fss_dir, 'AGP_100nt_fecal_even10k.biom')\n",
      "fssr_map_fp = pjoin(fss_dir, 'AGP_100nt_fecal_even10k.txt')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"github_download\"></a>\n",
      "#### Downloads the data from GitHub\n",
      "\n",
      "We now use cURL to download the data. If the data has already been downloaded, it will not be downloaded again unless the notebook is explicitly set to <code>Overwrite = <font color=\"green\">True</font></code>, which will always create or overwrite files."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Gets the biom file\n",
      "if not exists(raw_otu_fp) or overwrite:\n",
      "    # Downloads the compressed biom file\n",
      "    !curl -OL https://github.com/biocore/American-Gut/raw/master/data/AG/AG_100nt.biom.gz\n",
      "    # Unzips the biom file\n",
      "    !gunzip AG_100nt.biom.gz\n",
      "    # Moves the biom file to its final location\n",
      "    move(pjoin('.', 'AG_100nt.biom'), raw_otu_fp)\n",
      "\n",
      "if not exists(raw_map_fp) or overwrite:\n",
      "    # Downloads the mapping file\n",
      "    !wget https://github.com/biocore/American-Gut/raw/master/data/AG/AG_100nt.txt\n",
      "    move(pjoin('.', 'AG_100nt.txt'), raw_map_fp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
        "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:--  0:00:02 --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:--  0:00:03 --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:--  0:00:04 --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:--  0:00:05 --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:--  0:00:06 --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:--  0:00:07 --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:--  0:00:08 --:--:--     0\r",
        "100   152    0   152    0     0     17      0 --:--:--  0:00:08 --:--:--    39\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:--  0:00:09 --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:--  0:00:10 --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0     0    0     0    0     0      0      0 --:--:--  0:00:11 --:--:--     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  0 5838k    0 32768    0     0   2639      0  0:37:45  0:00:12  0:37:33 10224"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  1 5838k    1 63335    0     0   4509      0  0:22:05  0:00:14  0:21:51 13096"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  1 5838k    1 65536    0     0   4575      0  0:21:46  0:00:14  0:21:32 12812"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  2 5838k    2  155k    0     0  10471      0  0:09:30  0:00:15  0:09:15 32798"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  3 5838k    3  210k    0     0  13279      0  0:07:30  0:00:16  0:07:14 48108"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  4 5838k    4  257k    0     0  15298      0  0:06:30  0:00:17  0:06:13 48034"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  5 5838k    5  320k    0     0  17787      0  0:05:36  0:00:18  0:05:18 60394"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  5 5838k    5  336k    0     0  17671      0  0:05:38  0:00:19  0:05:19 54135"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  5 5838k    5  336k    0     0  16837      0  0:05:55  0:00:20  0:05:35 35402"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  6 5838k    6  374k    0     0  17592      0  0:05:39  0:00:21  0:05:18 30145"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  6 5838k    6  374k    0     0  16820      0  0:05:55  0:00:22  0:05:33 21520"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  6 5838k    6  376k    0     0  16547      0  0:06:01  0:00:23  0:05:38 11830"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  7 5838k    7  421k    0     0  17468      0  0:05:42  0:00:24  0:05:18 16712"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  7 5838k    7  421k    0     0  16788      0  0:05:56  0:00:25  0:05:31 16594"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  7 5838k    7  444k    0     0  16818      0  0:05:55  0:00:27  0:05:28 13628"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  7 5838k    7  452k    0     0  16884      0  0:05:54  0:00:27  0:05:27 17196"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  9 5838k    9  530k    0     0  18944      0  0:05:15  0:00:28  0:04:47 29251"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "  9 5838k    9  546k    0     0  18772      0  0:05:18  0:00:29  0:04:49 25083"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 10 5838k   10  585k    0     0  19460      0  0:05:07  0:00:30  0:04:37 32915"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 10 5838k   10  592k    0     0  19071      0  0:05:13  0:00:31  0:04:42 32005"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 10 5838k   10  593k    0     0  18766      0  0:05:18  0:00:32  0:04:46 29256"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 10 5838k   10  600k    0     0  18409      0  0:05:24  0:00:33  0:04:51 15177"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 10 5838k   10  600k    0     0  17874      0  0:05:34  0:00:34  0:05:00 12095"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 10 5838k   10  600k    0     0  17369      0  0:05:44  0:00:35  0:05:09  3455"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 10 5838k   10  608k    0     0  16776      0  0:05:56  0:00:37  0:05:19  3191"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 10 5838k   10  608k    0     0  16337      0  0:06:05  0:00:38  0:05:27  2762"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 10 5838k   10  608k    0     0  15919      0  0:06:15  0:00:39  0:05:36  1396"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 10 5838k   10  616k    0     0  15815      0  0:06:18  0:00:39  0:05:39  2831"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 10 5838k   10  632k    0     0  15833      0  0:06:17  0:00:40  0:05:37  5862"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 10 5838k   10  632k    0     0  15455      0  0:06:26  0:00:41  0:05:45  5072"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 10 5838k   10  639k    0     0  15429      0  0:06:27  0:00:42  0:05:45  7409"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 11 5838k   11  656k    0     0  15255      0  0:06:31  0:00:44  0:05:47  9921"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 11 5838k   11  656k    0     0  14916      0  0:06:40  0:00:45  0:05:55  7951"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 11 5838k   11  656k    0     0  14591      0  0:06:49  0:00:46  0:06:03  4738"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 11 5838k   11  656k    0     0  14281      0  0:06:58  0:00:47  0:06:11  4738"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 11 5838k   11  656k    0     0  13983      0  0:07:07  0:00:48  0:06:19  2949"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 11 5838k   11  656k    0     0  13698      0  0:07:16  0:00:49  0:06:27 "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "    0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 11 5838k   11  656k    0     0  13424      0  0:07:25  0:00:50  0:06:35     0"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 11 5838k   11  663k    0     0  13398      0  0:07:26  0:00:50  0:06:36  1626"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 11 5838k   11  680k    0     0  13516      0  0:07:22  0:00:51  0:06:31  5482"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 11 5838k   11  688k    0     0  13369      0  0:07:27  0:00:52  0:06:35  7031"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 11 5838k   11  694k    0     0  13293      0  0:07:29  0:00:53  0:06:36  8853"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 12 5838k   12  704k    0     0  13200      0  0:07:32  0:00:54  0:06:38 10743"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 12 5838k   12  712k    0     0  13038      0  0:07:38  0:00:55  0:06:43  9540"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 12 5838k   12  718k    0     0  12964      0  0:07:41  0:00:56  0:06:45  7498"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 12 5838k   12  720k    0     0  12719      0  0:07:50  0:00:57  0:06:53  6220"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 12 5838k   12  720k    0     0  12503      0  0:07:58  0:00:58  0:07:00  4754"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 12 5838k   12  725k    0     0  12547      0  0:07:56  0:00:59  0:06:57  4848"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 12 5838k   12  733k    0     0  12444      0  0:08:00  0:01:00  0:07:00  4989"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 12 5838k   12  757k    0     0  12653      0  0:07:52  0:01:01  0:06:51  8785"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 13 5838k   13  804k    0     0  13212      0  0:07:32  0:01:02  0:06:30 19773"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 14 5838k   14  864k    0     0  13983      0  0:07:07  0:01:03  0:06:04 34244"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 15 5838k   15  897k    0     0  14296      0  0:06:58  0:01:04  0:05:54 34761"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 15 5838k   15  929k    0     0  14589      0  0:06:49  0:01:05  0:05:44 41382"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 16 5838k   16  976k    0     0  15057      0  0:06:37  0:01:06  0:05:31 43956"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 17 5838k   17 1030k    0     0  15701      0  0:06:20  0:01:07  0:05:13 47375"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 18 5838k   18 1088k    0     0  16315      0  0:06:06  0:01:08  0:04:58 45747"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 19 5838k   19 1120k    0     0  16566      0  0:06:00  0:01:09  0:04:51 46183"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 20 5838k   20 1171k    0     0  17081      0  0:05:50  0:01:10  0:04:40 49560"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 20 5838k   20 1210k    0     0  17401      0  0:05:43  0:01:11  0:04:32 49476"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 21 5838k   21 1272k    0     0  18047      0  0:05:31  0:01:12  0:04:19 49580"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 22 5838k   22 1304k    0     0  18150      0  0:05:29  0:01:13  0:04:16 41859"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 22 5838k   22 1319k    0     0  18134      0  0:05:29  0:01:14  0:04:15 38678"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 25 5838k   25 1483k    0     0  20200      0  0:04:55  0:01:15  0:03:40 64012"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 26 5838k   26 1554k    0     0  20850      0  0:04:46  0:01:16  0:03:30 69033"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 26 5838k   26 1560k    0     0  20658      0  0:04:49  0:01:17  0:03:32 57566"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 27 5838k   27 1600k    0     0  20857      0  0:04:46  0:01:18  0:03:28 60505"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 27 5838k   27 1608k    0     0  20781      0  0:04:47  0:01:19  0:03:28 62580"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 30 5838k   30 1776k    0     0  22667      0  0:04:23  0:01:20  0:03:03 59654"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 32 5838k   32 1880k    0     0  23627      0  0:04:13  0:01:21  0:02:52 64737"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 33 5838k   33 1960k    0     0  24305      0  0:04:05  0:01:22  0:02:43 77882"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 34 5838k   34 1999k    0     0  24604      0  0:04:03  0:01:23  0:02:40 88388"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 34 5838k   34 2032k    0     0  24608      0  0:04:02  0:01:24  0:02:38 81581"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 35 5838k   35 2080k    0     0  24938      0  0:03:59  0:01:25  0:02:34 60142"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 36 5838k   36 2139k    0     0  25292      0  0:03:56  0:01:26  0:02:30 51552"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 36 5838k   36 2139k    0     0  25004      0  0:03:59  0:01:27  0:02:32 36457"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 36 5838k   36 2155k    0     0  24998      0  0:03:59  0:01:28  0:02:31 31440"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 39 5838k   39 2280k    0     0  26176      0  0:03:48  0:01:29  0:02:19 54651"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 41 5838k   41 2405k    0     0  27304      0  0:03:38  0:01:30  0:02:08 69288"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 43 5838k   43 2554k    0     0  28656      0  0:03:28  0:01:31  0:01:57 91695"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 45 5838k   45 2647k    0     0  29369      0  0:03:23  0:01:32  0:01:51  108k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 47 5838k   47 2752k    0     0  30107      0  0:03:18  0:01:33  0:01:45  112k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 48 5838k   48 2804k    0     0  30477      0  0:03:16  0:01:34  0:01:42  104k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 48 5838k   48 2835k    0     0  30271      0  0:03:17  0:01:35  0:01:42 77287"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 48 5838k   48 2835k    0     0  29958      0  0:03:19  0:01:36  0:01:43 51009"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 48 5838k   48 2840k    0     0  29705      0  0:03:21  0:01:37  0:01:44 35266"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 50 5838k   50 2952k    0     0  30717      0  0:03:14  0:01:38  0:01:36 42546"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 50 5838k   50 2960k    0     0  30488      0  0:03:16  0:01:39  0:01:37 30686"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 50 5838k   50 2960k    0     0  30171      0  0:03:18  0:01:40  0:01:38 28070"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 50 5838k   50 2960k    0     0  29873      0  0:03:20  0:01:41  0:01:39 28064"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 50 5838k   50 2960k    0     0  29582      0  0:03:22  0:01:42  0:01:40 26941"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 51 5838k   51 2991k    0     0  29464      0  0:03:22  0:01:43  0:01:39  7217"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 51 5838k   51 2992k    0     0  29361      0  0:03:23  0:01:44  0:01:39  6597"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 52 5838k   52 3046k    0     0  29642      0  0:03:21  0:01:45  0:01:36 18483"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 52 5838k   52 3093k    0     0  29590      0  0:03:22  0:01:47  0:01:35 24429"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 53 5838k   53 3104k    0     0  29644      0  0:03:21  0:01:47  0:01:34 30987"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 53 5838k   53 3112k    0     0  29368      0  0:03:23  0:01:48  0:01:35 27152"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 53 5838k   53 3116k    0     0  29097      0  0:03:25  0:01:49  0:01:36 23926"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 53 5838k   53 3124k    0     0  28991      0  0:03:26  0:01:50  0:01:36 15621"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 54 5838k   54 3163k    0     0  29075      0  0:03:25  0:01:51  0:01:34 16468"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 54 5838k   54 3210k    0     0  29290      0  0:03:24  0:01:52  0:01:32 21715"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 56 5838k   56 3296k    0     0  29814      0  0:03:20  0:01:53  0:01:27 40112"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 57 5838k   57 3344k    0     0  29981      0  0:03:19  0:01:54  0:01:25 51338"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 59 5838k   59 3448k    0     0  30456      0  0:03:16  0:01:55  0:01:21 59468"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 59 5838k   59 3452k    0     0  30355      0  0:03:16  0:01:56  0:01:20 58567"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 61 5838k   61 3569k    0     0  30969      0  0:03:13  0:01:58  0:01:15 63492"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 61 5838k   61 3576k    0     0  30909      0  0:03:13  0:01:58  0:01:15 54465"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 62 5838k   62 3624k    0     0  31131      0  0:03:12  0:01:59  0:01:13 57415"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 62 5838k   62 3648k    0     0  31053      0  0:03:12  0:02:00  0:01:12 46897"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 62 5838k   62 3663k    0     0  30821      0  0:03:13  0:02:01  0:01:12 41166"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 63 5838k   63 3688k    0     0  30898      0  0:03:13  0:02:02  0:01:11 28906"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 64 5838k   64 3757k    0     0  31226      0  0:03:11  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0:02:03  0:01:08 39153"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 65 5838k   65 3804k    0     0  31357      0  0:03:10  0:02:04  0:01:06 36726"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 65 5838k   65 3848k    0     0  31441      0  0:03:10  0:02:05  0:01:05 40723"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 66 5838k   66 3856k    0     0  31176      0  0:03:11  0:02:06  0:01:05 39937"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 67 5838k   67 3913k    0     0  31502      0  0:03:09  0:02:07  0:01:02 46284"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 67 5838k   67 3944k    0     0  31417      0  0:03:10  0:02:08  0:01:02 35848"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 67 5838k   67 3944k    0     0  31175      0  0:03:11  0:02:09  0:01:02 26934"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 70 5838k   70 4100k    0     0  32250      0  0:03:05  0:02:10  0:00:55 52994"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 72 5838k   72 4224k    0     0  32852      0  0:03:01  0:02:11  0:00:50 75200"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 76 5838k   76 4460k    0     0  34545      0  0:02:53  0:02:12  0:00:41  109k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 81 5838k   81 4768k    0     0  36652      0  0:02:43  0:02:13  0:00:30  176k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 83 5838k   83 4864k    0     0  37016      0  0:02:41  0:02:14  0:00:27  183k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 85 5838k   85 4968k    0     0  37614      0  0:02:38  0:02:15  0:00:23  172k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 87 5838k   87 5096k    0     0  38305      0  0:02:36  0:02:16  0:00:20  190k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 90 5838k   90 5264k    0     0  39292      0  0:02:32  0:02:17  0:00:15  161k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 92 5838k   92 5389k    0     0  39874      0  0:02:29  0:02:18  0:00:11  119k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 94 5838k   94 5538k    0     0  40739      0  0:02:26  0:02:19  0:00:07  144k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 97 5838k   97 5664k    0     0  41350      0  0:02:24  0:02:20  0:00:04  138k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 98 5838k   98 5733k    0     0  41577      0  0:02:23  0:02:21  0:00:02  127k"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "100 5838k  100 5838k    0     0  42048      0  0:02:22  0:02:22 --:--:--  115k\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "--2014-09-21 18:08:00--  https://github.com/biocore/American-Gut/raw/master/data/AG/AG_100nt.txt\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Resolving github.com... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "192.30.252.131\r\n",
        "Connecting to github.com|192.30.252.131|:443... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "connected.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "HTTP request sent, awaiting response... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "302 Found\r\n",
        "Location: https://raw.githubusercontent.com/biocore/American-Gut/master/data/AG/AG_100nt.txt [following]\r\n",
        "--2014-09-21 18:08:01--  https://raw.githubusercontent.com/biocore/American-Gut/master/data/AG/AG_100nt.txt\r\n",
        "Resolving raw.githubusercontent.com... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "23.235.44.133\r\n",
        "Connecting to raw.githubusercontent.com|23.235.44.133|:443... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "connected.\r\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "HTTP request sent, awaiting response... "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "200 OK\r\n",
        "Length: 6853534 (6.5M) [text/plain]\r\n",
        "Saving to: 'AG_100nt.txt'\r\n",
        "\r\n",
        "\r",
        " 0% [                                       ] 0           --.-K/s              "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 0% [                                       ] 23,334      57.2KB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 0% [                                       ] 47,334      73.0KB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 1% [                                       ] 79,334      86.8KB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 1% [                                       ] 119,334     98.6KB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 2% [                                       ] 175,334      123KB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 3% [>                                      ] 221,184      130KB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 3% [>                                      ] 263,334      129KB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 4% [>                                      ] 311,296      132KB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 5% [=>                                     ] 352,256      136KB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 5% [=>                                     ] 383,334      137KB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 5% [=>                                     ] 407,334      135KB/s             "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 6% [=>                                     ] 439,334      133KB/s  eta 47s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 6% [=>                                     ] 450,560      114KB/s  eta 47s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 6% [=>                                     ] 466,944      104KB/s  eta 60s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 8% [==>                                    ] 548,864      110KB/s  eta 60s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 8% [==>                                    ] 573,440      113KB/s  eta 60s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 8% [==>                                    ] 598,016      111KB/s  eta 57s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 8% [==>                                    ] 606,208     99.9KB/s  eta 57s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        " 9% [==>                                    ] 671,334     99.3KB/s  eta 57s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "10% [==>                                    ] 687,334     92.7KB/s  eta 59s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "10% [==>                                    ] 695,334     74.2KB/s  eta 59s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "10% [===>                                   ] 719,334     77.3KB/s  eta 66s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "11% [===>                                   ] 761,856     77.8KB/s  eta 66s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "11% [===>                                   ] 775,334     74.9KB/s  eta 66s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "11% [===>                                   ] 794,624     70.1KB/s  eta 66s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "11% [===>                                   ] 819,200     69.5KB/s  eta 66s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "12% [===>                                   ] 831,334     67.7KB/s  eta 64s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "12% [===>                                   ] 851,968     69.4KB/s  eta 64s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "12% [===>                                   ] 871,334     75.8KB/s  eta 64s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "12% [====>                                  ] 887,334     68.4KB/s  eta 64s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "13% [====>                                  ] 911,334     73.3KB/s  eta 64s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "13% [====>                                  ] 925,696     72.2KB/s  eta 63s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "13% [====>                                  ] 950,272     70.1KB/s  eta 63s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "14% [====>                                  ] 966,656     62.8KB/s  eta 70s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "14% [====>                                  ] 1,007,334   57.7KB/s  eta 70s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "14% [====>                                  ] 1,015,334   55.0KB/s  eta 70s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "14% [====>                                  ] 1,023,334   52.9KB/s  eta 73s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "15% [====>                                  ] 1,031,334   47.2KB/s  eta 82s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "15% [====>                                  ] 1,047,334   43.3KB/s  eta 82s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "15% [=====>                                 ] 1,087,334   37.9KB/s  eta 87s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "16% [=====>                                 ] 1,103,334   36.0KB/s  eta 87s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "16% [=====>                                 ] 1,111,334   25.6KB/s  eta 1m 44s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "16% [=====>                                 ] 1,143,334   23.9KB/s  eta 1m 46s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "16% [=====>                                 ] 1,151,334   22.2KB/s  eta 1m 46s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "16% [=====>                                 ] 1,159,334   20.5KB/s  eta 1m 51s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "17% [=====>                                 ] 1,171,456   18.9KB/s  eta 1m 51s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "17% [=====>                                 ] 1,179,648   17.9KB/s  eta 1m 56s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "17% [=====>                                 ] 1,183,334   16.3KB/s  eta 1m 56s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "17% [=====>                                 ] 1,187,840   15.9KB/s  eta 1m 56s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "17% [=====>                                 ] 1,191,334   16.1KB/s  eta 1m 56s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "17% [=====>                                 ] 1,199,334   13.8KB/s  eta 2m 0s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "17% [=====>                                 ] 1,204,224   13.5KB/s  eta 2m 0s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "17% [=====>                                 ] 1,212,416   14.8KB/s  eta 2m 0s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "17% [=====>                                 ] 1,223,334   14.8KB/s  eta 2m 3s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "17% [=====>                                 ] 1,228,800   12.4KB/s  eta 2m 3s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "17% [======>                                ] 1,231,334   12.9KB/s  eta 2m 3s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "18% [======>                                ] 1,236,992   12.1KB/s  eta 2m 3s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "18% [======>                                ] 1,245,184   12.1KB/s  eta 2m 7s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "18% [======>                                ] 1,255,334   16.9KB/s  eta 2m 7s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "18% [======>                                ] 1,261,568   13.6KB/s  eta 2m 7s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "18% [======>                                ] 1,269,760   11.1KB/s  eta 2m 22s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "19% [======>                                ] 1,327,104   15.3KB/s  eta 2m 22s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "19% [======>                                ] 1,335,296   16.1KB/s  eta 2m 22s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "19% [======>                                ] 1,343,334   15.9KB/s  eta 2m 18s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "19% [======>                                ] 1,351,334   16.3KB/s  eta 2m 18s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "19% [======>                                ] 1,367,334   14.0KB/s  eta 2m 30s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "20% [=======>                               ] 1,423,334   17.0KB/s  eta 2m 27s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "20% [=======>                               ] 1,431,334   14.2KB/s  eta 2m 37s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "21% [=======>                               ] 1,441,792   14.8KB/s  eta 2m 37s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "21% [=======>                               ] 1,471,334   16.3KB/s  eta 2m 37s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "21% [=======>                               ] 1,474,560   15.8KB/s  eta 2m 36s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "21% [=======>                               ] 1,479,334   13.5KB/s  eta 2m 45s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "22% [=======>                               ] 1,511,334   14.7KB/s  eta 2m 45s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "22% [=======>                               ] 1,515,520   14.7KB/s  eta 2m 45s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "22% [=======>                               ] 1,523,712   14.0KB/s  eta 2m 46s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "22% [=======>                               ] 1,548,288   15.0KB/s  eta 2m 46s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "22% [=======>                               ] 1,559,334   15.1KB/s  eta 2m 46s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "22% [=======>                               ] 1,564,672   15.2KB/s  eta 2m 44s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "23% [=======>                               ] 1,581,056   15.4KB/s  eta 2m 44s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "23% [========>                              ] 1,597,440   15.9KB/s  eta 2m 44s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "23% [========>                              ] 1,607,334   16.0KB/s  eta 2m 42s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "23% [========>                              ] 1,638,400   17.3KB/s  eta 2m 42s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "24% [========>                              ] 1,671,168   23.4KB/s  eta 2m 42s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "24% [========>                              ] 1,695,334   22.5KB/s  eta 2m 42s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "25% [========>                              ] 1,727,334   31.6KB/s  eta 2m 30s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "25% [========>                              ] 1,743,334   32.2KB/s  eta 2m 30s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "25% [=========>                             ] 1,759,334   31.0KB/s  eta 2m 30s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "25% [=========>                             ] 1,775,334   33.5KB/s  eta 2m 30s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "26% [=========>                             ] 1,794,048   45.5KB/s  eta 2m 27s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "26% [=========>                             ] 1,823,334   46.3KB/s  eta 2m 27s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "26% [=========>                             ] 1,835,008   48.1KB/s  eta 2m 27s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "27% [=========>                             ] 1,851,392   59.4KB/s  eta 2m 27s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "27% [=========>                             ] 1,871,334   59.6KB/s  eta 2m 22s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "27% [=========>                             ] 1,892,352   60.8KB/s  eta 2m 22s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "27% [=========>                             ] 1,911,334   65.8KB/s  eta 2m 22s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "28% [==========>                            ] 1,933,312   66.8KB/s  eta 2m 22s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "28% [==========>                            ] 1,957,888   69.0KB/s  eta 2m 16s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "28% [==========>                            ] 1,982,464   70.2KB/s  eta 2m 16s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "29% [==========>                            ] 1,998,848   71.1KB/s  eta 2m 16s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "29% [==========>                            ] 2,007,040   66.5KB/s  eta 2m 16s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "29% [==========>                            ] 2,023,334   59.5KB/s  eta 2m 13s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "29% [==========>                            ] 2,031,334   58.9KB/s  eta 2m 13s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "29% [==========>                            ] 2,047,334   54.2KB/s  eta 2m 13s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "29% [==========>                            ] 2,055,334   52.7KB/s  eta 2m 13s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "30% [==========>                            ] 2,071,334   53.5KB/s  eta 2m 11s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "30% [==========>                            ] 2,097,152   59.4KB/s  eta 2m 11s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "30% [===========>                           ] 2,111,334   56.0KB/s  eta 2m 11s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "31% [===========>                           ] 2,127,334   54.7KB/s  eta 2m 9s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "31% [===========>                           ] 2,143,334   55.2KB/s  eta 2m 9s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "31% [===========>                           ] 2,159,334   52.7KB/s  eta 2m 9s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "31% [===========>                           ] 2,175,334   52.5KB/s  eta 2m 9s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "32% [===========>                           ] 2,199,334   50.9KB/s  eta 2m 5s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "32% [===========>                           ] 2,228,224   42.8KB/s  eta 2m 5s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "33% [============>                          ] 2,310,144   44.5KB/s  eta 2m 1s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "34% [============>                          ] 2,383,334   50.9KB/s  eta 2m 1s  "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "34% [============>                          ] 2,391,334   45.8KB/s  eta 1m 58s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "35% [============>                          ] 2,447,334   49.3KB/s  eta 1m 58s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "36% [=============>                         ] 2,471,334   50.0KB/s  eta 1m 58s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "36% [=============>                         ] 2,495,334   50.0KB/s  eta 1m 53s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "36% [=============>                         ] 2,511,334   51.0KB/s  eta 1m 53s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "36% [=============>                         ] 2,523,136   50.8KB/s  eta 1m 53s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "37% [=============>                         ] 2,547,712   52.6KB/s  eta 1m 53s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "37% [=============>                         ] 2,555,904   52.0KB/s  eta 1m 51s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "37% [=============>                         ] 2,575,334   52.8KB/s  eta 1m 51s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "37% [=============>                         ] 2,580,480   50.1KB/s  eta 1m 51s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "37% [=============>                         ] 2,583,334   46.3KB/s  eta 1m 51s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "38% [=============>                         ] 2,631,334   50.5KB/s  eta 1m 51s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "38% [==============>                        ] 2,646,016   50.3KB/s  eta 1m 51s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "38% [==============>                        ] 2,655,334   50.9KB/s  eta 1m 51s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "39% [==============>                        ] 2,678,784   51.2KB/s  eta 1m 46s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "39% [==============>                        ] 2,711,334   49.7KB/s  eta 1m 46s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "40% [==============>                        ] 2,751,334   58.0KB/s  eta 1m 46s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "40% [==============>                        ] 2,768,896   58.3KB/s  eta 1m 42s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "40% [==============>                        ] 2,791,334   61.9KB/s  eta 1m 42s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "40% [==============>                        ] 2,807,334   58.6KB/s  eta 1m 42s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "41% [===============>                       ] 2,831,334   60.3KB/s  eta 1m 42s "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "41% [===============>                       ] 2,847,334   60.6KB/s  eta 99s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "41% [===============>                       ] 2,871,334   62.7KB/s  eta 99s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "41% [===============>                       ] 2,875,392   57.8KB/s  eta 99s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "42% [===============>                       ] 2,916,352   63.4KB/s  eta 99s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "42% [===============>                       ] 2,943,334   65.4KB/s  eta 95s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "43% [===============>                       ] 2,957,312   67.2KB/s  eta 95s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "43% [===============>                       ] 2,983,334   80.2KB/s  eta 95s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "43% [================>                      ] 2,991,334   73.3KB/s  eta 95s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "43% [================>                      ] 2,998,272   65.9KB/s  eta 94s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "44% [================>                      ] 3,022,848   68.5KB/s  eta 94s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "44% [================>                      ] 3,039,232   64.8KB/s  eta 94s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "44% [================>                      ] 3,047,334   61.1KB/s  eta 93s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "44% [================>                      ] 3,063,334   57.4KB/s  eta 93s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "44% [================>                      ] 3,071,334   54.8KB/s  eta 93s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "44% [================>                      ] 3,079,334   52.7KB/s  eta 93s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "45% [================>                      ] 3,095,334   50.6KB/s  eta 92s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "45% [================>                      ] 3,103,334   50.0KB/s  eta 92s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "45% [================>                      ] 3,111,334   46.1KB/s  eta 92s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "45% [================>                      ] 3,127,334   46.9KB/s  eta 92s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "45% [================>                      ] 3,129,344   44.4KB/s  eta 91s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "45% [================>                      ] 3,143,334   40.5KB/s  eta 91s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "46% [================>                      ] 3,153,920   41.7KB/s  eta 91s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "46% [=================>                     ] 3,167,334   37.0KB/s  eta 91s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "46% [=================>                     ] 3,170,304   34.0KB/s  eta 91s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "46% [=================>                     ] 3,186,688   30.1KB/s  eta 91s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "46% [=================>                     ] 3,207,334   33.4KB/s  eta 90s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "46% [=================>                     ] 3,215,334   30.5KB/s  eta 90s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "47% [=================>                     ] 3,235,840   32.2KB/s  eta 90s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "47% [=================>                     ] 3,268,608   35.7KB/s  eta 90s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "48% [=================>                     ] 3,301,376   42.1KB/s  eta 86s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "48% [==================>                    ] 3,342,336   46.1KB/s  eta 86s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "49% [==================>                    ] 3,391,334   53.0KB/s  eta 86s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "50% [==================>                    ] 3,431,334   60.1KB/s  eta 86s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "50% [==================>                    ] 3,455,334   61.0KB/s  eta 80s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "51% [==================>                    ] 3,495,334   69.0KB/s  eta 80s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "51% [===================>                   ] 3,538,944   75.7KB/s  eta 80s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "52% [===================>                   ] 3,571,712   88.0KB/s  eta 80s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "52% [===================>                   ] 3,629,056   99.8KB/s  eta 73s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "53% [===================>                   ] 3,686,400    119KB/s  eta 73s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "54% [====================>                  ] 3,727,334    125KB/s  eta 73s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "54% [====================>                  ] 3,759,334    132KB/s  eta 73s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "55% [====================>                  ] 3,823,334    146KB/s  eta 73s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "56% [=====================>                 ] 3,883,008    140KB/s  eta 64s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "58% [=====================>                 ] 4,022,272    158KB/s  eta 64s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "59% [======================>                ] 4,087,334    167KB/s  eta 64s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "60% [======================>                ] 4,119,334    159KB/s  eta 57s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "60% [======================>                ] 4,135,334    156KB/s  eta 57s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "61% [======================>                ] 4,210,688    161KB/s  eta 57s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "61% [=======================>               ] 4,243,456    163KB/s  eta 57s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "62% [=======================>               ] 4,300,800    177KB/s  eta 57s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "62% [=======================>               ] 4,317,184    169KB/s  eta 51s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "63% [=======================>               ] 4,333,568    162KB/s  eta 51s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "64% [=======================>               ] 4,390,912    170KB/s  eta 51s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "64% [========================>              ] 4,431,334    166KB/s  eta 51s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "64% [========================>              ] 4,448,256    160KB/s  eta 51s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "65% [========================>              ] 4,463,334    154KB/s  eta 47s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "65% [========================>              ] 4,519,334    159KB/s  eta 47s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "66% [========================>              ] 4,535,334    136KB/s  eta 45s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "68% [=========================>             ] 4,694,016    147KB/s  eta 45s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "69% [=========================>             ] 4,743,168    148KB/s  eta 45s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "69% [==========================>            ] 4,767,334    161KB/s  eta 39s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "69% [==========================>            ] 4,791,334    138KB/s  eta 39s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "70% [==========================>            ] 4,815,334    141KB/s  eta 39s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "70% [==========================>            ] 4,863,334    148KB/s  eta 39s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "71% [==========================>            ] 4,911,334    138KB/s  eta 36s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "71% [===========================>           ] 4,927,334    130KB/s  eta 36s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "72% [===========================>           ] 4,980,736    132KB/s  eta 36s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "73% [===========================>           ] 5,031,334    143KB/s  eta 36s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "73% [===========================>           ] 5,062,656    140KB/s  eta 36s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "74% [============================>          ] 5,103,334    138KB/s  eta 31s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "74% [============================>          ] 5,128,192    118KB/s  eta 31s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "76% [============================>          ] 5,259,264    135KB/s  eta 31s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "76% [============================>          ] 5,271,334    145KB/s  eta 31s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "77% [=============================>         ] 5,303,334    118KB/s  eta 31s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "77% [=============================>         ] 5,319,334    115KB/s  eta 27s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "77% [=============================>         ] 5,335,334    107KB/s  eta 27s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "79% [==============================>        ] 5,455,334    121KB/s  eta 27s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "79% [==============================>        ] 5,471,334    114KB/s  eta 24s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "80% [==============================>        ] 5,513,216    119KB/s  eta 24s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "80% [==============================>        ] 5,535,334    120KB/s  eta 24s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "80% [==============================>        ] 5,543,334    113KB/s  eta 24s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "81% [==============================>        ] 5,559,334    108KB/s  eta 24s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "81% [==============================>        ] 5,595,136    112KB/s  eta 22s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "81% [==============================>        ] 5,615,334   95.3KB/s  eta 22s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "82% [===============================>       ] 5,644,288   92.8KB/s  eta 22s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "83% [===============================>       ] 5,693,440   97.5KB/s  eta 22s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "83% [===============================>       ] 5,718,016   93.1KB/s  eta 22s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "84% [===============================>       ] 5,758,976   88.4KB/s  eta 19s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "85% [================================>      ] 5,855,334   94.3KB/s  eta 19s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "86% [================================>      ] 5,903,334   98.1KB/s  eta 19s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "86% [================================>      ] 5,922,816    100KB/s  eta 19s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "87% [=================================>     ] 5,975,334    113KB/s  eta 19s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "87% [=================================>     ] 6,007,334    119KB/s  eta 14s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "88% [=================================>     ] 6,062,080    108KB/s  eta 14s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "89% [=================================>     ] 6,103,040    118KB/s  eta 14s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "89% [=================================>     ] 6,143,334    119KB/s  eta 14s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "90% [==================================>    ] 6,175,334    122KB/s  eta 14s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "90% [==================================>    ] 6,223,334    129KB/s  eta 10s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "91% [==================================>    ] 6,239,334    124KB/s  eta 10s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "91% [==================================>    ] 6,255,334    145KB/s  eta 10s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "91% [==================================>    ] 6,283,264    144KB/s  eta 10s    "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "91% [==================================>    ] 6,303,334    128KB/s  eta 9s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "92% [===================================>   ] 6,340,608    138KB/s  eta 9s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "93% [===================================>   ] 6,422,528    134KB/s  eta 9s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "93% [===================================>   ] 6,438,912    129KB/s  eta 9s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "94% [===================================>   ] 6,447,104    115KB/s  eta 7s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "94% [===================================>   ] 6,463,334    113KB/s  eta 7s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "94% [===================================>   ] 6,487,334    108KB/s  eta 7s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "95% [====================================>  ] 6,519,334    104KB/s  eta 7s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "95% [====================================>  ] 6,545,408   95.4KB/s  eta 5s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "96% [====================================>  ] 6,583,334   90.1KB/s  eta 5s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "96% [====================================>  ] 6,602,752   86.2KB/s  eta 5s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "96% [====================================>  ] 6,623,334   85.1KB/s  eta 5s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "96% [====================================>  ] 6,635,520   71.8KB/s  eta 4s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "97% [====================================>  ] 6,676,480   71.9KB/s  eta 4s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "97% [=====================================> ] 6,701,056   74.6KB/s  eta 4s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "98% [=====================================> ] 6,717,440   67.0KB/s  eta 2s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "99% [=====================================> ] 6,815,334   76.9KB/s  eta 2s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "99% [=====================================> ] 6,823,334   78.6KB/s  eta 2s     "
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\r",
        "99% [=====================================> ] 6,847,334   77.0KB/s  eta 0s     \r",
        "100%[======================================>] 6,853,534   77.7KB/s   in 1m 50s \r\n",
        "\r\n",
        "2014-09-21 18:09:54 (61.0 KB/s) - 'AG_100nt.txt' saved [6853534/6853534]\r\n",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "<a id=\"splitsite\"></a>\n",
      "#### Splits the OTU table\n",
      "\n",
      "For more information on splitting out tables using a metadata field, see the <a href=\"http://qiime.org/scripts/split_otu_table.html\">Qiime documentation</a>. <br><em>Note: due to the size of the table, this may take a while to run.</em>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Splits the otu table by body site\n",
      "if not exists(ori_feces_otu_fp) or overwrite:\n",
      "    !split_otu_table.py -i $raw_otu_fp -m $raw_map_fp -f BODY_SITE -o $split_dir\n",
      "\n",
      "# Renames the fecal files to something tidier\n",
      "copy2(ori_feces_otu_fp, awtu_otu_fp)\n",
      "copy2(ori_feces_map_fp, awtu_map_fp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"clean_map\"></a>\n",
      "#### Cleans up mapping columns\n",
      "There are a set of mapping columns which are currently altered in the EBI submission. These three columns are <code>SEX</code>, <code>AGE_UNIT</code>, and <code>DOMINANT_HAND</code>. So, we will fix the values in these columns for the mapping file we plan to use in our analyses."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Reads in the raw otu table\n",
      "awtu_otu = load_table(awtu_otu_fp)\n",
      "awtu_map = pad_index(read_csv(awtu_map_fp,\n",
      "                             sep=txt_delim, \n",
      "                             na_values=map_nas,\n",
      "                             parse_dates = [42, 158, 134]),\n",
      "                    index_col=map_index)\n",
      "\n",
      "# Checks the samples in the mapping file are in the otu table, and the\n",
      "# samples in the otu table are in the map\n",
      "awtu_map = awtu_map.loc[awtu_otu.ids()]\n",
      "\n",
      "# Cleans up the sex information based on a miscoding\n",
      "awtu_map.loc[awtu_map.SEX == '47', 'SEX'] = 'male'\n",
      "awtu_map.loc[awtu_map.SEX == '48', 'SEX'] = 'female'\n",
      "\n",
      "# Cleans up age information based on miscodeing\n",
      "awtu_map.loc[awtu_map.AGE_UNIT == '78', 'AGE_UNIT'] = 'years'\n",
      "\n",
      "# Cleans up handedness based on miscoding\n",
      "awtu_map.loc[awtu_map.DOMINANT_HAND == '151', 'DOMINANT_HAND'] = 'left'\n",
      "awtu_map.loc[awtu_map.DOMINANT_HAND == '152', 'DOMINANT_HAND'] = 'right'\n",
      "awtu_map.loc[awtu_map.DOMINANT_HAND == '153', 'DOMINANT_HAND'] = 'ambidextrous'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"age_bin\"></a>\n",
      "######Age\n",
      "\n",
      "There are also a set of columns which are not included in the map, but may be useful for downstream anlyses. These include age binned by decade (<code>AGE_CAT</code>). While there are Qiime analyese which can handle simple, linear, regression, binning can help identify more complex patterns and simplify some of the noise.\n",
      "\n",
      "Here, we bin age by decade, with the exception of people under the age of 20. The gut develops in the first two years of life, and the guts of young children are signifigantly different than older children or adults [citation needed]."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Bins age by decade (with the exception of young children)\n",
      "def categorize_age(x):\n",
      "    if isnan(x):\n",
      "        return x\n",
      "    elif x < 3:\n",
      "        return \"baby\"\n",
      "    elif x < 13:\n",
      "        return \"child\"\n",
      "    elif x < 20:\n",
      "        return \"teen\"\n",
      "    elif x < 30:\n",
      "        return \"20s\"\n",
      "    elif x < 40:\n",
      "        return \"30s\"\n",
      "    elif x < 50:\n",
      "        return \"40s\"\n",
      "    elif x < 60:\n",
      "        return \"50s\"\n",
      "    elif x < 70:\n",
      "        return \"60s\"\n",
      "    else:\n",
      "        return \"70+\"\n",
      "awtu_map['AGE_CAT'] = awtu_map.AGE.apply(categorize_age)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"etoh_bin\"></a>\n",
      "######Alcohol Consumption\n",
      "\n",
      "Maps alcohol frequency into consumption."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def categorize_etoh(x):\n",
      "    if x == 'Never':\n",
      "        return \"No\"\n",
      "    elif isinstance(x, str):\n",
      "        return \"Yes\"\n",
      "    elif isnan(x):\n",
      "        return x\n",
      "    \n",
      "awtu_map['ALCOHOL_CONSUMPTION'] = awtu_map.ALCOHOL_FREQUENCY.apply(categorize_etoh)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"bmi_bin\"></a>\n",
      "######Body Mass Index\n",
      "\n",
      "Maps BMI into categories... more on this..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Categorizes the BMI into groups\n",
      "def categorize_bmi(x):\n",
      "    if isnan(x):\n",
      "        return x\n",
      "    elif x < 18.5:\n",
      "        return \"Underweight\"\n",
      "    elif x < 25:\n",
      "        return \"Normal\"\n",
      "    elif x < 30:\n",
      "        return \"Overweight\"\n",
      "    else:\n",
      "        return \"Obese\"\n",
      "awtu_map['BMI_CAT'] = awtu_map.BMI.apply(categorize_bmi)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"month_bin\"></a>\n",
      "######Collection Date\n",
      "\n",
      "Maps the collection date to the month and season, agnostic of year."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Categorizes data by collection month and collection season\n",
      "month_map = {1: ['January', 'Winter'],\n",
      "             2: ['February', 'Winter'],\n",
      "             3: ['March', 'Spring'],\n",
      "             4: ['April', 'Spring'],\n",
      "             5: ['May', 'Spring'],\n",
      "             6: ['June', 'Summer'],\n",
      "             7: ['July', 'Summer'],\n",
      "             8: ['August', 'Summer'],\n",
      "             9: ['September', 'Fall'],\n",
      "             10: ['October', 'Fall'],\n",
      "             11: ['November', 'Fall'],\n",
      "             12: ['December', 'Winter']}\n",
      "\n",
      "# Maps the data as a month\n",
      "awtu_map['COLLECTION_MONTH'] = \\\n",
      "    awtu_map.COLLECTION_DATE.apply(lambda x:month_map[x.month][0])\n",
      "\n",
      "# Maps the data as a season\n",
      "awtu_map['COLLECTION_SEASON'] = \\\n",
      "    awtu_map.COLLECTION_DATE.apply(lambda x:month_map[x.month][1])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"state_bin\"></a>\n",
      "######Collection Location\n",
      "\n",
      "We also check the collection state, to insure uniformity in analyses and remove any states which cannot clearly be identified. US States or Canadian providences can be encoded as two letter names (i.e. TX for Texas, BC for British Columbia), or by their full names. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Removes state information for any state not in the US \n",
      "# (This may change as additional countries are added.)\n",
      "countries = awtu_map.groupby('COUNTRY').count().STATE.index.values\n",
      "for country in countries:\n",
      "    if not country == 'GAZ:United States of America' and not country == 'GAZ:Canada':\n",
      "        awtu_map.loc[awtu_map.COUNTRY == country, 'STATE'] = nan\n",
      "\n",
      "# Handles regional mapping, cleaning up states so that only American and\n",
      "# Canadian states are included \n",
      "def check_state(x):\n",
      "    if isinstance(x, str) and x in us_state_map:\n",
      "        return us_state_map[x.upper()]\n",
      "    elif  isinstance(x, str) and x in canadian_map_english:\n",
      "        return canadian_map_english[x.upper()]\n",
      "    else:\n",
      "        return nan\n",
      "def census_f(x):\n",
      "    if  isinstance(x, str) and x in regions_by_state:\n",
      "        return regions_by_state[x]['Census_1']\n",
      "    else:\n",
      "        return nan\n",
      "\n",
      "def economic_f(x):\n",
      "    if isinstance(x, str) and  x in regions_by_state:\n",
      "        return regions_by_state[x]['Economic']\n",
      "    else:\n",
      "        return nan\n",
      "\n",
      "# Applies the functions\n",
      "awtu_map['STATE'] = awtu_map.STATE.apply(check_state)\n",
      "\n",
      "# Adds the census and economic regions\n",
      "awtu_map['CENSUS_REGION'] = awtu_map.STATE.apply(census_f)\n",
      "awtu_map['ECONOMIC_REGION'] = awtu_map.STATE.apply(economic_f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "<a id=\"id_subset\"></a>\n",
      "#### Splits the data into \"healthy\" subset\n",
      "\n",
      "<p>Certain health aspects of participants may have known influences on alpha diversity which overwhelms other potential influences. As a result, we chose to filter out individuals who may belong to a group which confounds the data.</p>\n",
      "<p><a href=\"http://www.pnas.org/content/108/Supplement_1/4554.long\">Recent antibiotic use</a> has been shown to affect alpha diversity; only participants who reported not using antibiotics in the last year were considered in this analysis.</p>\n",
      "<p><a href=\"\">Inflammatory Bowel Disease</a>, both <a href=\"http://www.nature.com/srep/2014/140122/srep03814/full/srep03814.html?message-global=remove\">Type I</a> and <a href=\"http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0009085\">Type II</a> diabetes are associated with lower alpha diversity than age-matched controls, so individuals with these conditions were also excluded.</p>\n",
      "<p><p>A relationship between <a href=\"http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2677729/\">Obesity</a> and lower alpha diversity has also been previously observed. In addition, we found that individuals who were considered underweight also had lower diversity than people in the \"normal\" or \"overweight\" BMI categories. As a result, we selected only to include subjects who had a BMI between 18.5 and 25.</p>\n",
      "<p>We start by removing anyone under the age of 20 for three reasons: <a href=\"http://www.nature.com/nature/journal/v486/n7402/full/nature11053.html\">young children</a> have low diversity compared to adults. <a href=\"http://win.niddk.nih.gov/statistics/\">BMI qualifications in children under 18</a> into categories such as \"underweight\", \"normal\", and \"overweight\" depend on the child's age and gender. Finally, we considered alcohol consumption as one of the variables which might affect alpha diversity in this study. Since the overwhelming majority of American Gut participants are American, we chose to set the lower limit of the age range near the legal drinking age to remove potential age-related biases among people who report never drinking.</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Reads in the mapping file\n",
      "if 'SUBSET' not in awtu_map.columns:\n",
      "    subset_f = {'AGE': lambda x: 19 < x and x < 70 and not isnan(x),\n",
      "                'DIABETES': lambda x: x == 'I do not have diabetes',\n",
      "                'IBD': lambda x: x == 'I do not have IBD',\n",
      "                'ANTIBIOTIC_SELECT': lambda x: x == 'Not in the last year',\n",
      "                'BMI': lambda x: 18.5 <= x < 30 and not isnan(x)}\n",
      "    \n",
      "    # Determines which samples meet the requirements of the categories\n",
      "    new_bin = {}\n",
      "    for cat, f in subset_f.iteritems():\n",
      "        new_bin[cat] = awtu_map[cat].apply(f)\n",
      "    \n",
      "    # Builds up the new binary dataframe\n",
      "    bin_frame = DataFrame(new_bin)\n",
      "    \n",
      "    # Adds a column to the current dataframe to look at the subset\n",
      "    bin_series = DataFrame(new_bin).all(1)\n",
      "    bin_series.name = 'SUBSET'\n",
      "    \n",
      "    awtu_map = awtu_map.join(bin_series)\n",
      "\n",
      "# Saves the updated mapping file\n",
      "awtu_map.loc[awtu_otu.ids()]\n",
      "awtu_map.to_csv(awtu_map_fp,\n",
      "                sep=txt_delim, \n",
      "                na_rep=write_na, \n",
      "                index_label=map_index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"filter\"></a>\n",
      "#### Filters the data to remove uncommon OTUs\n",
      "\n",
      "For some analyses, it may be useful to have a set of OTU tables with a single sample per individual. So, we'll read in the mapping file and OTU table, and use these to generate a set of OTUs which are a single sample per individiual. To maximize the number of samples which are retained, samples will be weighted based on the number of sequences in the samples."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if not exists(fwtu_otu_fp) or overwrite:\n",
      "    # Determines the number of samples in the OTU table\n",
      "    num_samps = awtu_otu.ids().shape[0]\n",
      "\n",
      "    # Calculates the number of samples in which an OTU must appear to not be filtered out\n",
      "    filt_count = int(min(ceil(num_samps*filt_frac), filt_num))\n",
      "\n",
      "    # Filters out the low abundance samples\n",
      "    obs_counts = Series(awtu_otu.nonzero_counts('observation'), \n",
      "                        index=awtu_otu.ids('observation'))\n",
      "    obs_keep = obs_counts[obs_counts > filt_count].index\n",
      "\n",
      "    # Gets the filtered table\n",
      "    fwtu_otu = awtu_otu.filter(obs_keep, axis='observation')\n",
      "    \n",
      "    # Gets the mapping file associated with the OTU table\n",
      "    fwtu_map = awtu_map.copy()\n",
      "\n",
      "    # Saves a copy of the updated mapping file in the raw and filtered directory\n",
      "    fwtu_map = awtu_map.loc[fwtu_otu.ids()]\n",
      "    fwtu_map.to_csv(fwtu_map_fp,\n",
      "                    sep=txt_delim, \n",
      "                    na_rep=write_na, \n",
      "                    index_label=map_index)\n",
      "    # Saves an updated copy of the mapping file\n",
      "    awtu_map.to_csv(awtu_map_fp,\n",
      "                    sep=txt_delim, \n",
      "                    na_rep=write_na, \n",
      "                    index_label=map_index)\n",
      "    \n",
      "    # Saves a copy of the filtered table\n",
      "    write_biom(fwtu_otu, fwtu_otu_fp)\n",
      "\n",
      "else:\n",
      "    fwtu_otu = load_table(fwtu_otu_fp)\n",
      "    fwtu_map = pad_index(read_csv(fwtu_map_fp,\n",
      "                             sep=txt_delim, \n",
      "                             na_values=map_nas,\n",
      "                             parse_dates = [42, 158, 134]),\n",
      "                         index_col=map_index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"rarefaction\"></a>\n",
      "#### Rarefies the data\n",
      "\n",
      "<p>Next, we rarify the data to 10,000 sequences per sample. This depth was chosen since it balances a better picture of diversity with retaining samples. Rarifaction begins by removing samples from the table which do not have the minimum number of counts. Sequences are then drawn randomly out of a weighted pool until we reach the appropriate number. We can repeat the process multiple times to increase the probability that uncommon taxa are selected.</p>\n",
      "\n",
      "<p>We will use this random subsampling technique ten times, which when averaged, is more likely to recapitulate the original diversity.<br><em>Note: due to the size of the table, this may take a while to run.</em></p>\n",
      "\n",
      "<p>We will begin by rarifying the unfiltered OTU table.</p>"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Preforms multiple rarifactions at an even depth\n",
      "if not exists(pjoin(sraw_rare_dir, rare_filepattern % (rarifaction_depth, 0))) or overwrite:\n",
      "    !multiple_rarefactions_even_depth.py -i $sawtu_map_fp -o $sraw_rare_dir -d $rarifaction_depth -n $num_rarifactions  --lineages_included\n",
      "    \n",
      "if not exists(pjoin(oraw_rare_dir, rare_filepattern % (rarifaction_depth, 0))) or overwrite:\n",
      "    !multiple_rarefactions_even_depth.py -i $oawtu_map_fp -o $oraw_rare_dir -d $rarifaction_depth -n $num_rarifactions  --lineages_included\n",
      "\n",
      "if not exists(pjoin(fraw_rare_dir, rare_filepattern % (rarifaction_depth, 0))) or overwrite:\n",
      "    !multiple_rarefactions_even_depth.py -i $fawtu_map_fp -o $fraw_rare_dir -d $rarifaction_depth -n $num_rarifactions  --lineages_included\n",
      "    \n",
      "if not exists(pjoin(ffilt_rare_dir, rare_filepattern % (rarifaction_depth, 0))) or overwrite:\n",
      "    !multiple_rarefactions_even_depth.py -i $ffwtu_otu_fp -o $ffilt_rare_dir -d $rarifaction_depth -n $num_rarifactions --lineages_included"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"alpha\"></a>\n",
      "#### Calculates the alpha diversity for the filtered and unfiltered table\n",
      "\n",
      "Alpha diversity is a measure of intra sample diversity, or how much variability we find in each sample. There are a variety of ways to calculate alpha diversity. This notebook will calculate four metrics: \n",
      "<a href=\"http://scikit-bio.org/docs/latest/generated/generated/skbio.diversity.alpha.observed_otus.html#skbio.diversity.alpha.observed_otus\">\n",
      "Observed Species Diversity</a>, \n",
      "<a href=\"http://scikit-bio.org/docs/latest/generated/generated/skbio.diversity.alpha.chao1.html#skbio.diversity.alpha.chao1\">\n",
      "Chao1 diversity,</a>\n",
      "<a href=\"http://scikit-bio.org/docs/latest/generated/generated/skbio.diversity.alpha.shannon.html#skbio.diversity.alpha.shannon\">\n",
      "Shannon entropy</a>, and \n",
      "<a href=\"http://www.sciencemag.org/content/308/5728/1635.full\">PD Whole Tree Diversity</a>. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Checks if the alpha rarefaction is necessary\n",
      "if not exists(awtr_map_fp) or not exists(fwtr_map_fp) or overwrite:\n",
      "    # Sets up a holding object for the alpha diversity\n",
      "    alpha_rounds_f = {'%s' % m:{} for m in alpha_metrics.split(',')}\n",
      "    alpha_rounds_r = {'%s' % m:{} for m in alpha_metrics.split(',')}\n",
      "\n",
      "    # Calculates alpha diversity for each rarefaction instance\n",
      "    for i in range(num_rarifactions):\n",
      "        # Sets up the filenames of the rarefaction instances\n",
      "        f_rare_fp = pjoin(filt_rare_dir, rare_filepattern % (rarifaction_depth, i))\n",
      "        r_rare_fp = pjoin(raw_rare_dir, rare_filepattern % (rarifaction_depth, i))\n",
      "\n",
      "        # Sets up the filenames for the alpha diversity tables\n",
      "        f_alpha_fp = pjoin(alpha_dir, alpha_filepattern % ('filt', rarifaction_depth, i))\n",
      "        r_alpha_fp = pjoin(alpha_dir, alpha_filepattern % ('raw', rarifaction_depth, i))\n",
      "\n",
      "        # Calculates the alpha diversity\n",
      "        if not exists(f_alpha_fp) or overwrite:\n",
      "            !alpha_diversity.py -i $f_rare_fp -o $f_alpha_fp -m $alpha_metrics -t $tree_fp\n",
      "        if not exists(r_alpha_fp) or overwrite:\n",
      "            !alpha_diversity.py -i $r_rare_fp -o $r_alpha_fp -m $alpha_metrics -t $tree_fp\n",
      "\n",
      "        # Reads in the alpha diversity\n",
      "        f_alpha = pad_index(read_csv(f_alpha_fp, sep=txt_delim), 'Unnamed: 0')\n",
      "        r_alpha = pad_index(read_csv(r_alpha_fp, sep=txt_delim), 'Unnamed: 0')\n",
      "\n",
      "        # Extracts the data\n",
      "        for col in alpha_rounds_f:\n",
      "            alpha_rounds_f['%s' % col]['%i' % i] = f_alpha[col]\n",
      "            alpha_rounds_f['%s' % col]['%i' % i].name = '%i' % i\n",
      "            alpha_rounds_r['%s' % col]['%i' % i] = r_alpha[col]\n",
      "            alpha_rounds_r['%s' % col]['%i' % i].name = '%i' % i\n",
      "\n",
      "        # Calculates metrics for each set of data\n",
      "        f_metrics = {}\n",
      "        r_metrics = {}\n",
      "        for metric in alpha_rounds_f:\n",
      "            f_metrics['%s_mean' % metric] = DataFrame(alpha_rounds_f[metric]).mean(1)\n",
      "            r_metrics['%s_mean' % metric] = DataFrame(alpha_rounds_r[metric]).mean(1)\n",
      "            f_metrics['%s_stdv' % metric] = DataFrame(alpha_rounds_f[metric]).std(1)\n",
      "            r_metrics['%s_stdv' % metric] = DataFrame(alpha_rounds_r[metric]).std(1)\n",
      "            f_metrics['%s_med' % metric] = DataFrame(alpha_rounds_f[metric]).median(1)\n",
      "            r_metrics['%s_med' % metric] = DataFrame(alpha_rounds_r[metric]).median(1)\n",
      "\n",
      "    # Converts the metrics to a single dataframe\n",
      "    r_alpha_df = DataFrame(r_metrics)\n",
      "    f_alpha_df = DataFrame(f_metrics)\n",
      "\n",
      "    # Appends the data to the mapping file\n",
      "    awtr_map = awtu_map.copy()\n",
      "    fwtr_map = fwtu_map.copy()\n",
      "    awtr_map = awtr_map.join(r_alpha_df)\n",
      "    fwtr_map = fwtr_map.join(f_alpha_df)\n",
      "\n",
      "    # Selects the appropriate metric\n",
      "    r_all_rounds = DataFrame(alpha_rounds_r[div_metric])\n",
      "    r_all_rounds = r_all_rounds.sort_index()\n",
      "    f_all_rounds = DataFrame(alpha_rounds_f[div_metric])\n",
      "    f_all_rounds = f_all_rounds.sort_index()\n",
      "\n",
      "    # Selects the means\n",
      "    r_alpha_df = r_alpha_df.sort_index()\n",
      "    f_alpha_df = f_alpha_df.sort_index()\n",
      "\n",
      "    # Calculates the distance between the two\n",
      "    r_mean_rounds = ([r_alpha_df['%s_mean' % div_metric].values]*ones((num_rarifactions, 1))).transpose()\n",
      "    r_diff = sqrt(square(r_all_rounds.values - r_mean_rounds))/r_mean_rounds\n",
      "    f_mean_rounds = ([f_alpha_df['%s_mean' % div_metric].values]*ones((num_rarifactions, 1))).transpose()\n",
      "    f_diff = sqrt(square(f_all_rounds.values - f_mean_rounds))/f_mean_rounds\n",
      "\n",
      "    # Determines the minimum distance\n",
      "    round_labels = arange(0, 10)\n",
      "    r_round_avg = r_diff.mean(0)\n",
      "    f_round_avg = f_diff.mean(0)\n",
      "\n",
      "    # Identifies the best round\n",
      "    r_best_rarifaction = round_labels[r_round_avg == min(r_round_avg)][0]\n",
      "    f_best_rarifaction = round_labels[f_round_avg == min(f_round_avg)][0]\n",
      "\n",
      "    # Copies the best round into a new folder to be used as the whole table file\n",
      "    copy2(pjoin(raw_rare_dir, rare_filepattern % (rarifaction_depth, r_best_rarifaction)), awtr_otu_fp)\n",
      "    copy2(pjoin(filt_rare_dir, rare_filepattern % (rarifaction_depth, f_best_rarifaction)), fwtr_otu_fp)\n",
      "\n",
      "    # Loads the OTU table\n",
      "    awtr_otu = load_table(awtr_otu_fp)\n",
      "    fwtr_otu = load_table(fwtr_otu_fp)\n",
      "\n",
      "    # Loads the rarefied OTU tables\n",
      "    awtr_map = awtr_map.loc[awtr_otu.ids()]\n",
      "    fwtr_map = fwtr_map.loc[fwtr_otu.ids()]\n",
      "    # Saves the updated file\n",
      "    awtr_map.to_csv(awtr_map_fp, \n",
      "                    sep=txt_delim, \n",
      "                    na_rep=write_na, \n",
      "                    index_label=map_index)\n",
      "    fwtr_map.to_csv(fwtr_map_fp, \n",
      "                    sep=txt_delim, \n",
      "                    na_rep=write_na, \n",
      "                    index_label=map_index)\n",
      "else:\n",
      "    # Loads the OTU table\n",
      "    awtr_otu = load_table(awtr_otu_fp)\n",
      "    fwtr_otu = load_table(fwtr_otu_fp)\n",
      "    awtr_map = pad_index(read_csv(awtr_map_fp,\n",
      "                                  sep=txt_delim, \n",
      "                                  na_values=map_nas,\n",
      "                                  parse_dates = [42, 158, 134]),\n",
      "                         index_col=map_index)\n",
      "\n",
      "    fwtr_map = pad_index(read_csv(fwtr_map_fp,\n",
      "                                  sep=txt_delim, \n",
      "                                  na_values=map_nas,\n",
      "                                  parse_dates = [42, 158, 134]),\n",
      "                         index_col=map_index)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"single\"></a>\n",
      "#### Identifies single samples in the OTU tables and mapping files.\n",
      "\n",
      "Single samples will be selected from the rarefied set, so the comparison can be made for samples which we know will can be used at at least the specified rarefaction depth. The samples will also be selected from the filtered table, to maximize the possibility they will appear in both the raw and the filtered tables.\n",
      "\n",
      "Individuals can be identified by the <code>HOST_SUBJECT_ID</code>."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if not exists(awsu_otu_fp) or not exists(fwsr_map_fp) or overwrite:\n",
      "    # Prealocates a place for the ids\n",
      "    single_ids = array([])\n",
      "\n",
      "    # Groups the filtered samples by the HOST SUBJECT ID\n",
      "    host_grouped = fwtr_map.groupby('HOST_SUBJECT_ID')\n",
      "\n",
      "    # Loops through the host subject IDS\n",
      "    for indv, ids in host_grouped.groups.iteritems():\n",
      "        # Checks if a single sample has been submitted or passed rarefaction\n",
      "        # for the indiviudal\n",
      "        if len(ids) == 1:\n",
      "            single_ids = hstack((single_ids, ids))\n",
      "        # Otherwise, a random sample is selected for the indiviudal\n",
      "        else:\n",
      "            single_ids = hstack((single_ids, choice(ids, 1)))\n",
      "\n",
      "    # Filters the OTU tables down to single samples\n",
      "    awsu_otu = awtu_otu.filter(single_ids)\n",
      "    fwsu_otu = fwtu_otu.filter(single_ids)\n",
      "    awsr_otu = awtr_otu.filter(single_ids)\n",
      "    fwsr_otu = fwtr_otu.filter(single_ids)\n",
      "\n",
      "    # Filters the mapping files down to single samples\n",
      "    awsu_map = awtu_map.loc[awsu_otu.ids()]\n",
      "    fwsu_map = fwtu_map.loc[fwsu_otu.ids()]\n",
      "    awsr_map = awtr_map.loc[awsr_otu.ids()]\n",
      "    fwsr_map = fwtr_map.loc[fwsr_otu.ids()]\n",
      "\n",
      "    # Saves the mapping files\n",
      "    awsu_map.to_csv(awsu_map_fp, \n",
      "                   sep=txt_delim, \n",
      "                   na_rep=write_na, \n",
      "                   index_label=map_index)\n",
      "    fwsu_map.to_csv(fwsu_map_fp, \n",
      "                   sep=txt_delim, \n",
      "                   na_rep=write_na, \n",
      "                   index_label=map_index)\n",
      "    awsr_map.to_csv(awsr_map_fp, \n",
      "                   sep=txt_delim, \n",
      "                   na_rep=write_na, \n",
      "                   index_label=map_index)\n",
      "    fwsr_map.to_csv(fwsr_map_fp, \n",
      "                    sep=txt_delim, \n",
      "                    na_rep=write_na, \n",
      "                    index_label=map_index)\n",
      "\n",
      "    # Saves the OTU tables\n",
      "    write_biom(awsu_otu, awsu_otu_fp)\n",
      "    write_biom(fwsu_otu, fwsu_otu_fp)\n",
      "    write_biom(awsr_otu, awsr_otu_fp)\n",
      "    write_biom(fwsr_otu, fwsr_otu_fp)\n",
      "\n",
      "else:\n",
      "    # Loads the mapping files\n",
      "    awsu_map = pad_index(read_csv(awsu_map_fp,\n",
      "                                  sep=txt_delim, \n",
      "                                  na_values=map_nas,\n",
      "                                  parse_dates = [42, 158, 134]),\n",
      "                         index_col=map_index)\n",
      "    fwsu_map = pad_index(read_csv(fwsu_map_fp,\n",
      "                                  sep=txt_delim, \n",
      "                                  na_values=map_nas,\n",
      "                                  parse_dates = [42, 158, 134]),\n",
      "                         index_col=map_index)\n",
      "    awsr_map = pad_index(read_csv(awsr_map_fp,\n",
      "                                  sep=txt_delim, \n",
      "                                  na_values=map_nas,\n",
      "                                  parse_dates = [42, 158, 134]),\n",
      "                         index_col=map_index)\n",
      "    fwsr_map = pad_index(read_csv(fwsr_map_fp,\n",
      "                                  sep=txt_delim, \n",
      "                                  na_values=map_nas,\n",
      "                                  parse_dates = [42, 158, 134]),\n",
      "                         index_col=map_index)\n",
      "    # Loads the OTU tables\n",
      "    awsu_map = load_table(awsu_map_fp)\n",
      "    fwsu_map = load_table(fwsu_map_fp)\n",
      "    awsr_map = load_table(awsr_map_fp)\n",
      "    fwsr_map = load_table(fwsr_map_fp)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"subset\"></a>\n",
      "#### Splits the table into the healthy subsets."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def save_subset_table(all_map, all_otu, sub_map_fp, sub_otu_fp):\n",
      "    \"\"\"Saves the subset data\"\"\"\n",
      "    # Writes the file if it does not exist\n",
      "    if not exists(sub_map_fp) or not exists(sub_otu_fp) or overwrite:\n",
      "        # Filters the mapping table to remove any samples not in the OTU table\n",
      "        all_map = all_map.loc[all_otu.ids()]\n",
      "\n",
      "        # Gets the subset table and otu table\n",
      "        sub_map = all_map.groupby('SUBSET').get_group(True)\n",
      "        sub_otu = all_otu.filter(sub_map.index.values)\n",
      "\n",
      "        # Saves the map and otu table\n",
      "        sub_map.to_csv(sub_map_fp, \n",
      "                       sep=txt_delim, \n",
      "                       na_rep=write_na, \n",
      "                       index_label=map_index)\n",
      "        write_biom(sub_otu, sub_otu_fp)\n",
      "\n",
      "# Sets up a set of maps, otus, and filepaths\n",
      "all_data = [[awtu_map, awtu_otu, astu_map_fp, astu_otu_fp],\n",
      "            [awtr_map, awtr_otu, astr_map_fp, astr_otu_fp],\n",
      "            [awsu_map, awsu_otu, assu_map_fp, assu_otu_fp],\n",
      "            [awsr_map, awsr_otu, assr_map_fp, assr_otu_fp],\n",
      "            [fwtu_map, fwtu_otu, fstu_map_fp, fstu_otu_fp],\n",
      "            [fwtr_map, fwtr_otu, fstr_map_fp, fstr_otu_fp],\n",
      "            [fwsu_map, fwsu_otu, fssu_map_fp, fssu_otu_fp],\n",
      "            [fwsr_map, fwsr_otu, fssr_map_fp, fssr_otu_fp]]\n",
      "\n",
      "# Loops through the data, and writes the subset data\n",
      "for save_set in all_data:\n",
      "    save_subset_table(*save_set)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<a href=\"#top\">Return to the top</a>\n",
      "\n",
      "<a id=\"beta\"></a>\n",
      "#### Gets the beta diversity for the tables\n",
      "\n",
      "We calculate weighted and unweighted \n",
      "<a href=\"http://aem.asm.org/content/71/12/8228.short\"> UniFrac</a> distance. Thi s is a phylogenetic metric..."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Sets up the list of file directories\n",
      "dirs = [(awt_dir, awtr_otu_fp), (fwt_dir, fwtr_otu_fp),\n",
      "        (ast_dir, astr_otu_fp), (fst_dir, fstr_otu_fp),\n",
      "        (aws_dir, awsr_otu_fp), (fws_dir, fwsr_otu_fp), \n",
      "        (ass_dir, assr_otu_fp), (fss_dir, fssr_otu_fp)]\n",
      "\n",
      "# Calculates the beta diverity for the tables\n",
      "for (out_dir, otu_fp) in dirs:\n",
      "    un_beta_fp = pjoin(out_dir, 'unweighted_unifrac_%s.txt' % split(otu_fp)[1].replace('.biom', ''))\n",
      "    we_beta_fp = pjoin(out_dir, 'weighted_unifrac_%s.txt' % split(otu_fp)[1].replace('.biom', ''))\n",
      "    if not exists(un_beta_fp) or not exists(we_beta_fp) or overwrite:\n",
      "        !beta_diversity.py -i $otu_fp -t $tree_fp -m $beta_metrics -o $out_dir"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We've now generated all the files needed for initial analysis. Other files which are needed will can be generated in the notebooks.\n",
      "\n",
      "<a href=\"#top\">Return to the top</a>"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}